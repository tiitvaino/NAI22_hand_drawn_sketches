{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tiitvaino/NAI22_hand_drawn_sketches/blob/main/initial_model_2tiit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pipIHNPSTLqT"
      },
      "source": [
        "# NAI 22 - initial model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "K6aUT6qYTLqV"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "lrezvslkTLqV"
      },
      "outputs": [],
      "source": [
        "# 1. layer of BiLSTM 1024 of hidden units\n",
        "# 2. layer of BiLSTM\n",
        "# classification head W with MLPs\n",
        "## 2048\n",
        "## 1024\n",
        "## 345\n",
        "\n",
        "# Adam optimiser with learning rate 1e-3\n",
        "\n",
        "# Train for 10 epochs with batch size of 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "j8pi3a3UTLqX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# https://analyticsindiamag.com/complete-guide-to-bidirectional-lstm-with-python-codes\n",
        "\n",
        "# Special activation function \n",
        "# https://stackoverflow.com/questions/43915482/how-do-you-create-a-custom-activation-function-with-keras\n",
        "\n",
        "# paper: https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Finding_Badly_Drawn_Bunnies_CVPR_2022_paper.pdf\n",
        "# data: https://github.com/googlecreativelab/quickdraw-dataset\n",
        "\n",
        "# Input \n",
        "#   What is the input, it dimensions?\n",
        "#   Should be in initial shape, [[x,y,t]]\n",
        "#   Look into sketch rnn\n",
        "#   https://arxiv.org/pdf/1704.03477.pdf It uses BILSTM\n",
        "\n",
        "#   what is the input layer, is it one dimensional?\n",
        "#   Should there be a layer/block of layers for input \n",
        "\n",
        "# Internal\n",
        "#   Should we make 4 models for each custom activation function\n",
        "#   Get classification working\n",
        "\n",
        "#   What is the bilstm activation function\n",
        "#   Use default\n",
        "\n",
        "\n",
        "# Custom activation functions\n",
        "#   Explain maybe these to us, they are quite unclear\n",
        "#   What does some of the symbols mean there?\n",
        "\n",
        "\n",
        "# Loss function\n",
        "#   What about loss function\n",
        "\n",
        "\n",
        "# output\n",
        "#   What should be output? Is it 345 classes, where each represents how well is this class drawn?\n",
        "\n",
        "#   Train on classification first to see if the network works\n",
        "#   Ask from the hpc.ut.ee to help with computation, add email also to Jaan. They should give access. through ssh.\n",
        "#   "
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "bf023SqNTLqX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-125-77b04939b63d>:52: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  bunny = np.array(bunny)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=400x400 at 0x7F5185EC6E20>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "bunny = [\n",
        "  [\n",
        "    [216.69900512695312, 209.3179931640625, 199.6300048828125, 193.0229949951172, 180.29600524902344, 174.6739959716797, 169.8000030517578, 164.9080047607422, 156.16400146484375, 151.89199829101562, 145.41299438476562, 139.63299560546875, 134.13999938964844, 131.11300659179688, 129.58399963378906, 130.05299377441406, 132.28700256347656, 136.75, 144.1699981689453, 151.10000610351562, 157.08599853515625, 163.8350067138672, 173.24000549316406, 178.78700256347656, 186.02499389648438, 193.0189971923828, 197.7949981689453, 201.83099365234375, 208.5189971923828, 217.53900146484375, 223.2740020751953, 228.02699279785156, 232.2790069580078, 238.572998046875, 242.30099487304688, 243.60000610351562, 245.5989990234375, 246.06199645996094, 245.4250030517578, 242.4600067138672, 236.5030059814453, 236.5030059814453],\n",
        "    [118.26499938964844, 120.9949951171875, 121.08999633789062, 121.5989990234375, 122.97999572753906, 123.63200378417969, 124.52999877929688, 126.0469970703125, 129.1300048828125, 131.4199981689453, 134.69500732421875, 139.9219970703125, 146.38600158691406, 153.3820037841797, 159.14700317382812, 165.13400268554688, 170.4010009765625, 174.1619873046875, 176.18798828125, 177.92098999023438, 177.95199584960938, 178.45401000976562, 177.4849853515625, 177.718994140625, 177.718994140625, 176.9849853515625, 177.218994140625, 176.4849853515625, 175.25299072265625, 171.05300903320312, 167.0830078125, 162.85598754882812, 158.864990234375, 149.8990020751953, 142.70599365234375, 136.9340057373047, 129.46499633789062, 120.82699584960938, 113.89599609375, 109.10000610351562, 109.03399658203125, 109.03399658203125],\n",
        "    [0, 116, 152, 187, 192, 203, 217, 236, 278, 287, 318, 351, 387, 420, 454, 488, 522, 557, 590, 608, 624, 644, 658, 681, 694, 711, 728, 745, 763, 796, 813, 829, 851, 885, 897, 916, 938, 953, 988, 1019, 1053, 1088]\n",
        "  ],\n",
        "  [\n",
        "    [184.24400329589844, 184.24400329589844],\n",
        "    [153.73800659179688, 153.73800659179688],\n",
        "    [1535, 1601]\n",
        "  ],\n",
        "  [\n",
        "    [184.24400329589844, 184.24400329589844],\n",
        "    [152.73800659179688, 152.73800659179688],\n",
        "    [2149, 2219]\n",
        "  ],\n",
        "  [\n",
        "    [161.2760009765625, 159.7779998779297],\n",
        "    [148.24200439453125, 149.24099731445312],\n",
        "    [2645, 2717]\n",
        "  ],\n",
        "  [\n",
        "    [152.28799438476562, 157.95399475097656, 161.97999572753906, 169.875, 176.40699768066406, 182.15899658203125, 190.21499633789062, 197.59800720214844, 203.86000061035156, 209.61399841308594, 214.3730010986328, 219.39700317382812, 224.1230010986328, 230.11599731445312, 234.87600708007812, 237.86900329589844],\n",
        "    [130.25599670410156, 134.2220001220703, 134.5679931640625, 134.7530059814453, 134.01699829101562, 133.7530059814453, 131.13600158691406, 129.28900146484375, 128.0229949951172, 127.02400207519531, 127.25799560546875, 129.7239990234375, 131.22300720214844, 134.2209930419922, 136.718994140625, 136.75100708007812],\n",
        "    [3499, 3617, 3626, 3654, 3698, 3725, 3752, 3793, 3820, 3853, 3886, 3941, 3979, 4022, 4082, 4122]\n",
        "  ],\n",
        "  [\n",
        "    [160.77699279785156, 155.78399658203125, 148.88800048828125, 144.28900146484375, 138.38699340820312, 131.38099670410156, 127.61599731445312, 124.65899658203125, 122.88999938964844, 120.9000015258789, 118.86699676513672, 118.33599853515625, 126.45899963378906, 131.41700744628906, 137.39500427246094, 145.06500244140625, 152.08599853515625, 156.11199951171875, 160.39700317382812, 164.87100219726562, 171.39999389648438, 176.19500732421875, 180.68600463867188, 183.6790008544922, 185.71200561523438, 188.20799255371094, 191.43699645996094, 194.43299865722656, 198.16600036621094],\n",
        "    [117.26600646972656, 114.76800537109375, 107.63400268554688, 102.97999572753906, 95.38900756835938, 84.65299987792969, 77.64799499511719, 73.4320068359375, 67.22099304199219, 62.477996826171875, 55.677001953125, 50.647003173828125, 51.78399658203125, 52.78300476074219, 53.78599548339844, 55.514007568359375, 57.02000427246094, 58.51100158691406, 60.75199890136719, 64.20799255371094, 71.44000244140625, 77.20700073242188, 83.197998046875, 88.68899536132812, 94.45899963378906, 100.68600463867188, 106.68099975585938, 111.94200134277344, 114.4739990234375],\n",
        "    [5611, 5664, 5721, 5738, 5764, 5816, 5835, 5858, 5889, 5897, 5924, 5952, 6056, 6081, 6094, 6109, 6125, 6144, 6159, 6190, 6211, 6243, 6283, 6312, 6346, 6386, 6413, 6448, 6495]\n",
        "  ],\n",
        "  [\n",
        "    [226.18600463867188, 234.4029998779297, 239.87899780273438, 245.2010040283203, 252.4320068359375, 259.0039978027344, 264.5450134277344, 270.52899169921875, 276.5159912109375, 281.27899169921875, 286.2770080566406, 290.2980041503906, 291.8299865722656, 290.86199951171875, 289.6300048828125, 287.1700134277344, 282.9570007324219, 280.2120056152344, 275.0190124511719, 264.635009765625, 259.8290100097656, 256.03900146484375, 251.97500610351562, 248.45599365234375],\n",
        "    [107.77400207519531, 102.177001953125, 97.21800231933594, 92.71200561523438, 87.21099853515625, 81.24099731445312, 76.62100219726562, 74.09700012207031, 72.5679931640625, 71.5679931640625, 72.03599548339844, 75.00100708007812, 82.20399475097656, 86.66600036621094, 92.12600708007812, 97.84199523925781, 106.31100463867188, 113.76699829101562, 121.99299621582031, 135.89599609375, 142.7270050048828, 149.74899291992188, 155.88101196289062, 159.16598510742188],\n",
        "    [6883, 7015, 7037, 7052, 7064, 7114, 7145, 7165, 7203, 7235, 7279, 7322, 7382, 7396, 7411, 7421, 7440, 7457, 7482, 7496, 7507, 7525, 7560, 7631]\n",
        "  ],\n",
        "  [\n",
        "    [186.24099731445312, 181.7480010986328, 175.75599670410156, 171.26199340820312, 166.33399963378906, 161.83599853515625, 155.88400268554688, 147.92100524902344, 142.4010009765625, 138.3699951171875, 132.38299560546875, 129.1199951171875, 126.125, 124.59100341796875, 123.09500122070312, 123.3290023803711, 124.06300354003906, 125.06099700927734, 126.06199645996094, 127.05999755859375, 128.79100036621094, 130.78199768066406, 133.28399658203125, 136.51400756835938, 139.74099731445312, 142.51100158691406, 146.7239990234375, 151.21800231933594, 156.95199584960938, 166.3979949951172, 172.1300048828125, 178.15199279785156, 184.15499877929688, 191.3769989013672, 197.093994140625, 202.89500427246094, 209.60699462890625, 215.60899353027344, 220.36900329589844, 224.625, 230.58599853515625, 234.83900451660156, 236.61199951171875, 237.8699951171875, 237.9040069580078, 236.93499755859375, 234.9759979248047, 231.9949951171875, 227.31500244140625, 222.5780029296875, 213.40699768066406, 207.9250030517578, 203.8820037841797, 198.13900756835938, 189.70899963378906, 185.1840057373047, 181.14300537109375, 176.80599975585938, 176.2550048828125],\n",
        "    [178.218994140625, 179.21798706054688, 178.218994140625, 178.218994140625, 178.218994140625, 178.218994140625, 179.45098876953125, 179.21798706054688, 180.45001220703125, 182.18499755859375, 186.4119873046875, 190.64199829101562, 196.60400390625, 203.3489990234375, 211.0679931640625, 217.82501220703125, 224.8280029296875, 231.81900024414062, 237.59201049804688, 243.58401489257812, 250.80499267578125, 257.0469970703125, 263.0610046386719, 269.78900146484375, 275.0459899902344, 279.8210144042969, 284.2959899902344, 287.3290100097656, 290.8320007324219, 293.593994140625, 293.62799072265625, 292.89599609375, 291.1600036621094, 288.4289855957031, 285.2229919433594, 281.9309997558594, 278.4410095214844, 275.43798828125, 270.70599365234375, 264.97900390625, 258.7489929199219, 250.56399536132812, 243.1099853515625, 235.17401123046875, 224.73599243164062, 218.1510009765625, 212.89999389648438, 206.12100219726562, 201.1300048828125, 196.35699462890625, 188.44198608398438, 184.13198852539062, 181.58099365234375, 179.5419921875, 177.77801513671875, 176.52200317382812, 176.48599243164062, 176.22000122070312, 176.22000122070312],\n",
        "    [8984, 9135, 9234, 9283, 9325, 9353, 9393, 9420, 9456, 9496, 9541, 9584, 9613, 9644, 9688, 9718, 9745, 9785, 9815, 9848, 9888, 9919, 9948, 9987, 10042, 10073, 10107, 10127, 10162, 10221, 10248, 10270, 10306, 10339, 10381, 10412, 10445, 10485, 10513, 10553, 10589, 10614, 10631, 10649, 10668, 10694, 10711, 10724, 10736, 10753, 10773, 10797, 10817, 10831, 10850, 10864, 10882, 10914, 10995]\n",
        "  ],\n",
        "  [\n",
        "    [149.79200744628906, 142.63600158691406, 136.40699768066406, 131.64199829101562, 127.3949966430664, 125.35800170898438, 124.01499938964844, 122.36100006103516, 120.13600158691406, 118.11599731445312, 115.86299896240234, 119.83399963378906, 125.52899932861328, 131.97999572753906, 137.74600219726562, 142.302001953125, 137.3090057373047],\n",
        "    [290.1310119628906, 290.1310119628906, 292.0979919433594, 295.3320007324219, 298.8210144042969, 305.75799560546875, 309.8030090332031, 315.5190124511719, 321.8489990234375, 326.90399169921875, 331.31201171875, 335.59600830078125, 337.3290100097656, 338.32598876953125, 338.5929870605469, 340.5920104980469, 345.5880126953125],\n",
        "    [11627, 11690, 11728, 11793, 11808, 11840, 11855, 11895, 11931, 11951, 12002, 12291, 12398, 12455, 12499, 12596, 12750]\n",
        "  ]\n",
        "]\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "import cv2\n",
        "\n",
        "bunny = np.array(bunny)\n",
        "bunny.shape\n",
        "bunny_stroke_loc =  [list(zip(stroke[0],stroke[1]))for stroke in bunny]\n",
        "max(bunny_stroke_loc)\n",
        "\n",
        "image = np.full((400,400,3),(255,255,255),dtype=np.uint8)\n",
        "for stroke in bunny_stroke_loc:\n",
        "  last_point = int(stroke[0][0]),int(stroke[0][1])\n",
        "  for x,y in stroke:\n",
        "    x,y = int(x),int(y)\n",
        "    cv2.line(image, last_point, (x,y), (0,0,0), 2)\n",
        "    last_point = (x,y)\n",
        "display(Image.fromarray(image))"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Dkg66jkzTLqX",
        "outputId": "6509b532-1ac6-4bb4-be5f-adb50138d526",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gsutil -mq cp 'gs://quickdraw_dataset/full/simplified/*.ndjson' ."
      ],
      "metadata": {
        "id": "75Sm1SNHh16m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "# Find file names\n",
        "data_files = os.listdir()\n",
        "data_files = list(filter(lambda x: '.ndjson' in x, data_files))"
      ],
      "metadata": {
        "id": "IhW_HhqL2xHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data(file_name, max_nr_elements):\n",
        "  df = pd.DataFrame(columns= ['word', 'countrycode', 'timestamp', 'recognized', 'key_id', 'drawing'])\n",
        "  with open(file_name) as f:\n",
        "    for row in f.readlines():\n",
        "      data = json.loads(row)\n",
        "      df_row = pd.DataFrame.from_dict(data,orient='index').T\n",
        "      max_nr_elements-=1\n",
        "      df = df.append([df_row])\n",
        "      if max_nr_elements == 0:\n",
        "        break\n",
        "  # get only good pictures\n",
        "  df = df[df.recognized == True]\n",
        "  return df\n"
      ],
      "metadata": {
        "id": "T4NKk7KU4FFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data_files)"
      ],
      "metadata": {
        "id": "O1xic0feajrw",
        "outputId": "65acc96c-30df-4658-e708-f9ee687863e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "345"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#List of classes\n",
        "data_files"
      ],
      "metadata": {
        "id": "kp-RENwuncnn",
        "outputId": "6472558d-5605-459e-c369-bacd077d9e31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['lollipop.ndjson',\n",
              " 'raccoon.ndjson',\n",
              " 'vase.ndjson',\n",
              " 'broccoli.ndjson',\n",
              " 'remote control.ndjson',\n",
              " 'basket.ndjson',\n",
              " 'flip flops.ndjson',\n",
              " 'lion.ndjson',\n",
              " 'rake.ndjson',\n",
              " 'bathtub.ndjson',\n",
              " 'stereo.ndjson',\n",
              " 'mouth.ndjson',\n",
              " 'eraser.ndjson',\n",
              " 'saw.ndjson',\n",
              " 'cooler.ndjson',\n",
              " 'grass.ndjson',\n",
              " 'megaphone.ndjson',\n",
              " 'leg.ndjson',\n",
              " 'mug.ndjson',\n",
              " 'picture frame.ndjson',\n",
              " 'passport.ndjson',\n",
              " 'mouse.ndjson',\n",
              " 'binoculars.ndjson',\n",
              " 'asparagus.ndjson',\n",
              " 'hammer.ndjson',\n",
              " 'garden.ndjson',\n",
              " 'train.ndjson',\n",
              " 'dolphin.ndjson',\n",
              " 'helicopter.ndjson',\n",
              " 'matches.ndjson',\n",
              " 'panda.ndjson',\n",
              " 'purse.ndjson',\n",
              " 'barn.ndjson',\n",
              " 'flamingo.ndjson',\n",
              " 'sock.ndjson',\n",
              " 'teapot.ndjson',\n",
              " 'bulldozer.ndjson',\n",
              " 'nail.ndjson',\n",
              " 'submarine.ndjson',\n",
              " 'donut.ndjson',\n",
              " 'carrot.ndjson',\n",
              " 'airplane.ndjson',\n",
              " 'hot tub.ndjson',\n",
              " 'spoon.ndjson',\n",
              " 'headphones.ndjson',\n",
              " 'tent.ndjson',\n",
              " 'elbow.ndjson',\n",
              " 'mailbox.ndjson',\n",
              " 'keyboard.ndjson',\n",
              " 'pineapple.ndjson',\n",
              " 'streetlight.ndjson',\n",
              " 'spreadsheet.ndjson',\n",
              " 'trombone.ndjson',\n",
              " 'cake.ndjson',\n",
              " 'hexagon.ndjson',\n",
              " 'pants.ndjson',\n",
              " 'hamburger.ndjson',\n",
              " 'peas.ndjson',\n",
              " 'fan.ndjson',\n",
              " 'chandelier.ndjson',\n",
              " 'door.ndjson',\n",
              " 'shark.ndjson',\n",
              " 'bed.ndjson',\n",
              " 'candle.ndjson',\n",
              " 'wristwatch.ndjson',\n",
              " 'computer.ndjson',\n",
              " 'stove.ndjson',\n",
              " 'mountain.ndjson',\n",
              " 'clock.ndjson',\n",
              " 'moustache.ndjson',\n",
              " 'hand.ndjson',\n",
              " 'pizza.ndjson',\n",
              " 'triangle.ndjson',\n",
              " 'camel.ndjson',\n",
              " 'canoe.ndjson',\n",
              " 'string bean.ndjson',\n",
              " 'giraffe.ndjson',\n",
              " 'popsicle.ndjson',\n",
              " 'sun.ndjson',\n",
              " 'hospital.ndjson',\n",
              " 'basketball.ndjson',\n",
              " 'bandage.ndjson',\n",
              " 'snorkel.ndjson',\n",
              " 'foot.ndjson',\n",
              " 'finger.ndjson',\n",
              " 'elephant.ndjson',\n",
              " 'snail.ndjson',\n",
              " 'dresser.ndjson',\n",
              " 'necklace.ndjson',\n",
              " 'scissors.ndjson',\n",
              " 'toothpaste.ndjson',\n",
              " 'feather.ndjson',\n",
              " 'moon.ndjson',\n",
              " 'envelope.ndjson',\n",
              " 'wine bottle.ndjson',\n",
              " 'blueberry.ndjson',\n",
              " 'skyscraper.ndjson',\n",
              " 'hot air balloon.ndjson',\n",
              " 'saxophone.ndjson',\n",
              " 'smiley face.ndjson',\n",
              " 'lantern.ndjson',\n",
              " 'bread.ndjson',\n",
              " 'pond.ndjson',\n",
              " 'The Mona Lisa.ndjson',\n",
              " 'coffee cup.ndjson',\n",
              " 'underwear.ndjson',\n",
              " 'wine glass.ndjson',\n",
              " 'cactus.ndjson',\n",
              " 'owl.ndjson',\n",
              " 'monkey.ndjson',\n",
              " 'hockey puck.ndjson',\n",
              " 'stethoscope.ndjson',\n",
              " 'circle.ndjson',\n",
              " 'pliers.ndjson',\n",
              " 'tiger.ndjson',\n",
              " 'flower.ndjson',\n",
              " 'sea turtle.ndjson',\n",
              " 'zigzag.ndjson',\n",
              " 'house plant.ndjson',\n",
              " 'anvil.ndjson',\n",
              " 'spider.ndjson',\n",
              " 'pool.ndjson',\n",
              " 'belt.ndjson',\n",
              " 'see saw.ndjson',\n",
              " 'waterslide.ndjson',\n",
              " 'bowtie.ndjson',\n",
              " 'lightning.ndjson',\n",
              " 'laptop.ndjson',\n",
              " 'crayon.ndjson',\n",
              " 'house.ndjson',\n",
              " 'pillow.ndjson',\n",
              " 'umbrella.ndjson',\n",
              " 'drums.ndjson',\n",
              " 'animal migration.ndjson',\n",
              " 'dumbbell.ndjson',\n",
              " 'arm.ndjson',\n",
              " 'screwdriver.ndjson',\n",
              " 'sailboat.ndjson',\n",
              " 'onion.ndjson',\n",
              " 'leaf.ndjson',\n",
              " 'piano.ndjson',\n",
              " 'trumpet.ndjson',\n",
              " 'frying pan.ndjson',\n",
              " 'diamond.ndjson',\n",
              " 'bus.ndjson',\n",
              " 'swing set.ndjson',\n",
              " 'bush.ndjson',\n",
              " 'calculator.ndjson',\n",
              " 'bottlecap.ndjson',\n",
              " 'toilet.ndjson',\n",
              " 'ant.ndjson',\n",
              " 'sheep.ndjson',\n",
              " 'ocean.ndjson',\n",
              " 'line.ndjson',\n",
              " 'harp.ndjson',\n",
              " 'snowman.ndjson',\n",
              " 'dishwasher.ndjson',\n",
              " 'table.ndjson',\n",
              " 'shoe.ndjson',\n",
              " 'crab.ndjson',\n",
              " 'pear.ndjson',\n",
              " 'stop sign.ndjson',\n",
              " 'church.ndjson',\n",
              " 'cup.ndjson',\n",
              " 'hourglass.ndjson',\n",
              " 'hedgehog.ndjson',\n",
              " 'bicycle.ndjson',\n",
              " 'duck.ndjson',\n",
              " 'lobster.ndjson',\n",
              " 'brain.ndjson',\n",
              " 'knife.ndjson',\n",
              " 'yoga.ndjson',\n",
              " 'suitcase.ndjson',\n",
              " 'hat.ndjson',\n",
              " 'ice cream.ndjson',\n",
              " 'beach.ndjson',\n",
              " 'butterfly.ndjson',\n",
              " 'stairs.ndjson',\n",
              " 'fish.ndjson',\n",
              " 'angel.ndjson',\n",
              " 'tornado.ndjson',\n",
              " 'apple.ndjson',\n",
              " 'police car.ndjson',\n",
              " 'roller coaster.ndjson',\n",
              " 'kangaroo.ndjson',\n",
              " 'campfire.ndjson',\n",
              " 'rainbow.ndjson',\n",
              " 'couch.ndjson',\n",
              " 'speedboat.ndjson',\n",
              " 'compass.ndjson',\n",
              " 'guitar.ndjson',\n",
              " 'ladder.ndjson',\n",
              " 'microphone.ndjson',\n",
              " 'aircraft carrier.ndjson',\n",
              " 'zebra.ndjson',\n",
              " 'cloud.ndjson',\n",
              " 'river.ndjson',\n",
              " 'horse.ndjson',\n",
              " 'broom.ndjson',\n",
              " 'alarm clock.ndjson',\n",
              " 'ear.ndjson',\n",
              " 'flying saucer.ndjson',\n",
              " 'jail.ndjson',\n",
              " 'drill.ndjson',\n",
              " 'radio.ndjson',\n",
              " 'fire hydrant.ndjson',\n",
              " 'telephone.ndjson',\n",
              " 'tooth.ndjson',\n",
              " 'pencil.ndjson',\n",
              " 'tennis racquet.ndjson',\n",
              " 'parrot.ndjson',\n",
              " 'garden hose.ndjson',\n",
              " 'helmet.ndjson',\n",
              " 'bench.ndjson',\n",
              " 'blackberry.ndjson',\n",
              " 'cell phone.ndjson',\n",
              " 'oven.ndjson',\n",
              " 'knee.ndjson',\n",
              " 'paintbrush.ndjson',\n",
              " 'syringe.ndjson',\n",
              " 'stitches.ndjson',\n",
              " 'mushroom.ndjson',\n",
              " 'eye.ndjson',\n",
              " 'peanut.ndjson',\n",
              " 'strawberry.ndjson',\n",
              " 'boomerang.ndjson',\n",
              " 'lipstick.ndjson',\n",
              " 'paint can.ndjson',\n",
              " 'cannon.ndjson',\n",
              " 'mermaid.ndjson',\n",
              " 'parachute.ndjson',\n",
              " 'birthday cake.ndjson',\n",
              " 'swan.ndjson',\n",
              " 'rifle.ndjson',\n",
              " 'bracelet.ndjson',\n",
              " 'car.ndjson',\n",
              " 'scorpion.ndjson',\n",
              " 'lighthouse.ndjson',\n",
              " 'sweater.ndjson',\n",
              " 'snowflake.ndjson',\n",
              " 'soccer ball.ndjson',\n",
              " 'grapes.ndjson',\n",
              " 'axe.ndjson',\n",
              " 'golf club.ndjson',\n",
              " 'shovel.ndjson',\n",
              " 'rain.ndjson',\n",
              " 'wheel.ndjson',\n",
              " 'snake.ndjson',\n",
              " 'camera.ndjson',\n",
              " 'sink.ndjson',\n",
              " 'potato.ndjson',\n",
              " 'sword.ndjson',\n",
              " 'pickup truck.ndjson',\n",
              " 'watermelon.ndjson',\n",
              " 'paper clip.ndjson',\n",
              " 'dog.ndjson',\n",
              " 'banana.ndjson',\n",
              " 'firetruck.ndjson',\n",
              " 'television.ndjson',\n",
              " 'whale.ndjson',\n",
              " 'fireplace.ndjson',\n",
              " 'frog.ndjson',\n",
              " 'beard.ndjson',\n",
              " 'toe.ndjson',\n",
              " 'face.ndjson',\n",
              " 'cello.ndjson',\n",
              " 'rollerskates.ndjson',\n",
              " 'bear.ndjson',\n",
              " 'cruise ship.ndjson',\n",
              " 'traffic light.ndjson',\n",
              " 'backpack.ndjson',\n",
              " 'squirrel.ndjson',\n",
              " 'key.ndjson',\n",
              " 'flashlight.ndjson',\n",
              " 'marker.ndjson',\n",
              " 'toothbrush.ndjson',\n",
              " 'squiggle.ndjson',\n",
              " 'microwave.ndjson',\n",
              " 'cat.ndjson',\n",
              " 'eyeglasses.ndjson',\n",
              " 'floor lamp.ndjson',\n",
              " 'The Great Wall of China.ndjson',\n",
              " 'nose.ndjson',\n",
              " 'The Eiffel Tower.ndjson',\n",
              " 'rabbit.ndjson',\n",
              " 'octopus.ndjson',\n",
              " 'jacket.ndjson',\n",
              " 'teddy-bear.ndjson',\n",
              " 'crown.ndjson',\n",
              " 'school bus.ndjson',\n",
              " 'light bulb.ndjson',\n",
              " 'square.ndjson',\n",
              " 'ceiling fan.ndjson',\n",
              " 'hockey stick.ndjson',\n",
              " 'skull.ndjson',\n",
              " 'lighter.ndjson',\n",
              " 'penguin.ndjson',\n",
              " 'bucket.ndjson',\n",
              " 'van.ndjson',\n",
              " 'hurricane.ndjson',\n",
              " 'steak.ndjson',\n",
              " 'tree.ndjson',\n",
              " 'tractor.ndjson',\n",
              " 'diving board.ndjson',\n",
              " 'sandwich.ndjson',\n",
              " 'camouflage.ndjson',\n",
              " 'cookie.ndjson',\n",
              " 'hot dog.ndjson',\n",
              " 'clarinet.ndjson',\n",
              " 'windmill.ndjson',\n",
              " 'star.ndjson',\n",
              " 'sleeping bag.ndjson',\n",
              " 'castle.ndjson',\n",
              " 'dragon.ndjson',\n",
              " 'fork.ndjson',\n",
              " 'violin.ndjson',\n",
              " 'skateboard.ndjson',\n",
              " 'goatee.ndjson',\n",
              " 'map.ndjson',\n",
              " 'palm tree.ndjson',\n",
              " 'toaster.ndjson',\n",
              " 'rhinoceros.ndjson',\n",
              " 'bee.ndjson',\n",
              " 'bird.ndjson',\n",
              " 'bridge.ndjson',\n",
              " 'bat.ndjson',\n",
              " 'cow.ndjson',\n",
              " 'baseball bat.ndjson',\n",
              " 'motorbike.ndjson',\n",
              " 'octagon.ndjson',\n",
              " 'calendar.ndjson',\n",
              " 'shorts.ndjson',\n",
              " 'fence.ndjson',\n",
              " 'mosquito.ndjson',\n",
              " 'crocodile.ndjson',\n",
              " 'chair.ndjson',\n",
              " 'postcard.ndjson',\n",
              " 'washing machine.ndjson',\n",
              " 'power outlet.ndjson',\n",
              " 'baseball.ndjson',\n",
              " 'pig.ndjson',\n",
              " 'truck.ndjson',\n",
              " 'ambulance.ndjson',\n",
              " 'book.ndjson',\n",
              " 't-shirt.ndjson']"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_sketches = pd.DataFrame(columns= ['word', 'countrycode', 'timestamp', 'recognized', 'key_id', 'drawing'])"
      ],
      "metadata": {
        "id": "nd3-wPqHa3J5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read some amount of sketches\n",
        "for data_file in data_files[:10]:\n",
        "  df_sketches = df_sketches.append([read_data(data_file, 1000)])\n"
      ],
      "metadata": {
        "id": "YjgS46Gxaf4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_org = df_sketches"
      ],
      "metadata": {
        "id": "Wolbt-g8pIYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose only certain classes\n",
        "df_sketches = df_sketches[(df_sketches['word']=='lollipop') | (df_sketches['word']=='vase')]"
      ],
      "metadata": {
        "id": "cJBg5E8HnykI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "df_sketches = df_sketches.sample(frac = 1)\n",
        "\n",
        "# Extract each sketch\n",
        "sketches = df_sketches.drawing.to_list()\n",
        "\n",
        "# Find sketches unique class names\n",
        "sketch_classes_names = df_sketches.word.str.get_dummies().columns\n",
        "# Make one hot vector from classes\n",
        "sketch_classes_onehot = df_sketches.word.str.get_dummies().values.tolist()\n",
        "sketch_classes_names"
      ],
      "metadata": {
        "id": "C6RcYbFYqq-T",
        "outputId": "aed42692-d5ef-40b7-f706-2287bcdb17af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['lollipop', 'vase'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 321
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find out maximal dimensions \n",
        "max_line_len = max([len(x) for sketch in sketches for line in sketch for x in line ])\n",
        "max_storkes_len = max([len(x)for x in sketches])\n",
        "\n",
        "print('nr of sketches: ',len(sketches))\n",
        "print('nr of max strokes per sketch: ',max_storkes_len)\n",
        "print('coordinates dimensions: ',max([len(x) for line in sketches for x in line]))\n",
        "print('nr of max points per stroke: ', max_line_len)"
      ],
      "metadata": {
        "id": "ygnAJ5XJrBtc",
        "outputId": "0e345ab9-d6b1-4cf1-c2d8-886aa0fe0136",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nr of sketches:  1929\n",
            "nr of max strokes per sketch:  14\n",
            "coordinates dimensions:  2\n",
            "nr of max points per stroke:  101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize\n",
        "sketch_norms = []\n",
        "for sketch in sketches:\n",
        "  sketch_norm = []\n",
        "  for line in sketch:\n",
        "    x,y = line\n",
        "    # Make strokes into equal lenght\n",
        "    x = ([0]* (max_line_len - len(x) if len(x)<max_line_len else 0) + x)[:max_line_len]\n",
        "    y = ([0]* (max_line_len - len(y) if len(y)<max_line_len else 0) + y)[:max_line_len]\n",
        "    # Normalize x and y values\n",
        "    sketch_norm.append(np.array([np.array(x)/255,np.array(y)/255]))\n",
        "  #sketch_norm = ([[np.array([0]*max_line_len),np.array([0]*max_line_len)]]\\\n",
        "  #              *(max_storkes_len - len(sketch_norm) if len(sketch_norm)<max_storkes_len else 0)\\\n",
        "  #              + sketch_norm)[:max_storkes_len]\n",
        "  sketch_norms.append(np.array(sketch_norm))\n",
        "\n",
        "sketch_norms = np.array(sketch_norms)\n",
        "sketch_norms.shape\n",
        "                    "
      ],
      "metadata": {
        "id": "bNp4dwnYtLm7",
        "outputId": "c2a3ace9-468d-4699-bce3-a4502c998bc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-331-2ffbd43b04ed>:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  sketch_norms = np.array(sketch_norms)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1929,)"
            ]
          },
          "metadata": {},
          "execution_count": 331
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Bidirectional\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Activation, Dense, Reshape\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "FK722hRHm__q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nr_of_training_pictures = 1000"
      ],
      "metadata": {
        "id": "L7HxiJ-0p-iI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sketch_classes_onehot[:20]"
      ],
      "metadata": {
        "id": "hvgmxjftt6dY",
        "outputId": "d18a1532-6bb3-4de0-b994-28a786d89679",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 0],\n",
              " [0, 1],\n",
              " [1, 0],\n",
              " [0, 1],\n",
              " [0, 1],\n",
              " [0, 1],\n",
              " [0, 1],\n",
              " [0, 1],\n",
              " [0, 1],\n",
              " [1, 0],\n",
              " [1, 0],\n",
              " [1, 0],\n",
              " [1, 0],\n",
              " [1, 0],\n",
              " [1, 0],\n",
              " [1, 0],\n",
              " [0, 1],\n",
              " [1, 0],\n",
              " [1, 0],\n",
              " [1, 0]]"
            ]
          },
          "metadata": {},
          "execution_count": 334
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sketch_norms[0].shape[1]"
      ],
      "metadata": {
        "id": "i06kGbRXxggn",
        "outputId": "771ba315-535b-4eb2-a9c8-e60d218bd358",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 2, 101)"
            ]
          },
          "metadata": {},
          "execution_count": 336
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model.add(Bidirectional(LSTM(1024, input_shape=(-1,sketch_norms[0].shape[1], sketch_norms[0].shape[2])))) # biLSTM two layer\n",
        "model.add(Reshape((1, 2048), input_shape = (1,2048)))\n",
        "model.add(Bidirectional(LSTM(1024)))\n",
        "model.add(keras.layers.Dense(2048)) # MLP 2048-1024-345\n",
        "model.add(keras.layers.Dense(1024))\n",
        "model.add(keras.layers.Dense(len(sketch_classes_onehot[0]),activation='softmax'))#345)) # , activation='custom'\n",
        "#sgdr = CyclicLR(min_lr=0.0, max_lr=0.05, base_epochs=10, mul_epochs=2)\n",
        "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "i = 0\n",
        "for sketch_norm, sketch_class in zip(sketch_norms[:nr_of_training_pictures],sketch_classes_onehot[:nr_of_training_pictures]):\n",
        "  print(i, sketch_classes_names[np.array(sketch_class).argmax()])\n",
        "  model.train_on_batch(sketch_norm,\n",
        "            np.array([sketch_class]*len(sketch_norm)))\n",
        "  i+=1\n",
        "\n",
        "\n",
        "\n",
        "#SGDR (Cosine Annealing) Callback for Keras: https://gist.github.com/Callidior/747eb767862c9d48f9d900a6373b16d1\n",
        "#def learning_rate(epoch):\n",
        "#  return min_lr + 0.5 * (max_lr - min_lr) * (1 + cos(pi * epoch/num_epochs))"
      ],
      "metadata": {
        "id": "O52uTio6nBba",
        "outputId": "5e35bb3a-17d3-4d2d-d6cd-849c898083ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 lollipop\n",
            "1 vase\n",
            "2 lollipop\n",
            "3 vase\n",
            "4 vase\n",
            "5 vase\n",
            "6 vase\n",
            "7 vase\n",
            "8 vase\n",
            "9 lollipop\n",
            "10 lollipop\n",
            "11 lollipop\n",
            "12 lollipop\n",
            "13 lollipop\n",
            "14 lollipop\n",
            "15 lollipop\n",
            "16 vase\n",
            "17 lollipop\n",
            "18 lollipop\n",
            "19 lollipop\n",
            "20 lollipop\n",
            "21 vase\n",
            "22 vase\n",
            "23 vase\n",
            "24 vase\n",
            "25 lollipop\n",
            "26 lollipop\n",
            "27 lollipop\n",
            "28 lollipop\n",
            "29 vase\n",
            "30 vase\n",
            "31 vase\n",
            "32 lollipop\n",
            "33 lollipop\n",
            "34 lollipop\n",
            "35 vase\n",
            "36 lollipop\n",
            "37 vase\n",
            "38 lollipop\n",
            "39 lollipop\n",
            "40 lollipop\n",
            "41 lollipop\n",
            "42 lollipop\n",
            "43 lollipop\n",
            "44 vase\n",
            "45 lollipop\n",
            "46 vase\n",
            "47 vase\n",
            "48 lollipop\n",
            "49 vase\n",
            "50 vase\n",
            "51 vase\n",
            "52 vase\n",
            "53 lollipop\n",
            "54 lollipop\n",
            "55 vase\n",
            "56 lollipop\n",
            "57 lollipop\n",
            "58 vase\n",
            "59 lollipop\n",
            "60 vase\n",
            "61 vase\n",
            "62 lollipop\n",
            "63 vase\n",
            "64 vase\n",
            "65 vase\n",
            "66 vase\n",
            "67 lollipop\n",
            "68 vase\n",
            "69 vase\n",
            "70 vase\n",
            "71 lollipop\n",
            "72 lollipop\n",
            "73 lollipop\n",
            "74 vase\n",
            "75 vase\n",
            "76 lollipop\n",
            "77 lollipop\n",
            "78 vase\n",
            "79 vase\n",
            "80 lollipop\n",
            "81 lollipop\n",
            "82 lollipop\n",
            "83 vase\n",
            "84 vase\n",
            "85 vase\n",
            "86 vase\n",
            "87 lollipop\n",
            "88 vase\n",
            "89 lollipop\n",
            "90 vase\n",
            "91 vase\n",
            "92 lollipop\n",
            "93 vase\n",
            "94 vase\n",
            "95 lollipop\n",
            "96 lollipop\n",
            "97 lollipop\n",
            "98 lollipop\n",
            "99 vase\n",
            "100 lollipop\n",
            "101 vase\n",
            "102 vase\n",
            "103 lollipop\n",
            "104 vase\n",
            "105 vase\n",
            "106 lollipop\n",
            "107 vase\n",
            "108 lollipop\n",
            "109 vase\n",
            "110 lollipop\n",
            "111 vase\n",
            "112 lollipop\n",
            "113 vase\n",
            "114 lollipop\n",
            "115 vase\n",
            "116 vase\n",
            "117 vase\n",
            "118 lollipop\n",
            "119 lollipop\n",
            "120 lollipop\n",
            "121 lollipop\n",
            "122 lollipop\n",
            "123 lollipop\n",
            "124 vase\n",
            "125 lollipop\n",
            "126 lollipop\n",
            "127 vase\n",
            "128 vase\n",
            "129 vase\n",
            "130 vase\n",
            "131 lollipop\n",
            "132 lollipop\n",
            "133 lollipop\n",
            "134 vase\n",
            "135 vase\n",
            "136 vase\n",
            "137 lollipop\n",
            "138 vase\n",
            "139 lollipop\n",
            "140 lollipop\n",
            "141 vase\n",
            "142 lollipop\n",
            "143 lollipop\n",
            "144 lollipop\n",
            "145 vase\n",
            "146 lollipop\n",
            "147 lollipop\n",
            "148 vase\n",
            "149 lollipop\n",
            "150 vase\n",
            "151 vase\n",
            "152 lollipop\n",
            "153 vase\n",
            "154 lollipop\n",
            "155 vase\n",
            "156 lollipop\n",
            "157 vase\n",
            "158 vase\n",
            "159 vase\n",
            "160 vase\n",
            "161 lollipop\n",
            "162 lollipop\n",
            "163 lollipop\n",
            "164 vase\n",
            "165 lollipop\n",
            "166 vase\n",
            "167 vase\n",
            "168 vase\n",
            "169 vase\n",
            "170 vase\n",
            "171 lollipop\n",
            "172 lollipop\n",
            "173 lollipop\n",
            "174 lollipop\n",
            "175 vase\n",
            "176 lollipop\n",
            "177 vase\n",
            "178 vase\n",
            "179 lollipop\n",
            "180 lollipop\n",
            "181 lollipop\n",
            "182 lollipop\n",
            "183 vase\n",
            "184 vase\n",
            "185 vase\n",
            "186 vase\n",
            "187 lollipop\n",
            "188 vase\n",
            "189 vase\n",
            "190 vase\n",
            "191 lollipop\n",
            "192 vase\n",
            "193 lollipop\n",
            "194 lollipop\n",
            "195 lollipop\n",
            "196 lollipop\n",
            "197 lollipop\n",
            "198 lollipop\n",
            "199 lollipop\n",
            "200 lollipop\n",
            "201 vase\n",
            "202 vase\n",
            "203 vase\n",
            "204 lollipop\n",
            "205 vase\n",
            "206 vase\n",
            "207 lollipop\n",
            "208 lollipop\n",
            "209 vase\n",
            "210 lollipop\n",
            "211 lollipop\n",
            "212 vase\n",
            "213 lollipop\n",
            "214 vase\n",
            "215 vase\n",
            "216 lollipop\n",
            "217 lollipop\n",
            "218 vase\n",
            "219 lollipop\n",
            "220 vase\n",
            "221 lollipop\n",
            "222 lollipop\n",
            "223 vase\n",
            "224 lollipop\n",
            "225 vase\n",
            "226 lollipop\n",
            "227 lollipop\n",
            "228 vase\n",
            "229 vase\n",
            "230 lollipop\n",
            "231 vase\n",
            "232 lollipop\n",
            "233 lollipop\n",
            "234 vase\n",
            "235 vase\n",
            "236 vase\n",
            "237 vase\n",
            "238 vase\n",
            "239 lollipop\n",
            "240 vase\n",
            "241 lollipop\n",
            "242 vase\n",
            "243 vase\n",
            "244 lollipop\n",
            "245 vase\n",
            "246 lollipop\n",
            "247 lollipop\n",
            "248 vase\n",
            "249 lollipop\n",
            "250 vase\n",
            "251 vase\n",
            "252 lollipop\n",
            "253 vase\n",
            "254 lollipop\n",
            "255 lollipop\n",
            "256 vase\n",
            "257 vase\n",
            "258 vase\n",
            "259 lollipop\n",
            "260 lollipop\n",
            "261 lollipop\n",
            "262 vase\n",
            "263 lollipop\n",
            "264 lollipop\n",
            "265 vase\n",
            "266 vase\n",
            "267 lollipop\n",
            "268 lollipop\n",
            "269 vase\n",
            "270 vase\n",
            "271 vase\n",
            "272 lollipop\n",
            "273 vase\n",
            "274 lollipop\n",
            "275 lollipop\n",
            "276 vase\n",
            "277 vase\n",
            "278 lollipop\n",
            "279 vase\n",
            "280 vase\n",
            "281 lollipop\n",
            "282 lollipop\n",
            "283 vase\n",
            "284 lollipop\n",
            "285 vase\n",
            "286 lollipop\n",
            "287 vase\n",
            "288 lollipop\n",
            "289 vase\n",
            "290 lollipop\n",
            "291 lollipop\n",
            "292 lollipop\n",
            "293 vase\n",
            "294 vase\n",
            "295 lollipop\n",
            "296 vase\n",
            "297 lollipop\n",
            "298 vase\n",
            "299 lollipop\n",
            "300 vase\n",
            "301 lollipop\n",
            "302 lollipop\n",
            "303 vase\n",
            "304 lollipop\n",
            "305 lollipop\n",
            "306 vase\n",
            "307 lollipop\n",
            "308 vase\n",
            "309 lollipop\n",
            "310 vase\n",
            "311 vase\n",
            "312 lollipop\n",
            "313 vase\n",
            "314 vase\n",
            "315 vase\n",
            "316 vase\n",
            "317 vase\n",
            "318 vase\n",
            "319 lollipop\n",
            "320 lollipop\n",
            "321 vase\n",
            "322 vase\n",
            "323 lollipop\n",
            "324 vase\n",
            "325 lollipop\n",
            "326 lollipop\n",
            "327 lollipop\n",
            "328 vase\n",
            "329 vase\n",
            "330 vase\n",
            "331 lollipop\n",
            "332 lollipop\n",
            "333 vase\n",
            "334 vase\n",
            "335 lollipop\n",
            "336 lollipop\n",
            "337 lollipop\n",
            "338 lollipop\n",
            "339 vase\n",
            "340 vase\n",
            "341 vase\n",
            "342 lollipop\n",
            "343 lollipop\n",
            "344 vase\n",
            "345 vase\n",
            "346 lollipop\n",
            "347 vase\n",
            "348 vase\n",
            "349 lollipop\n",
            "350 lollipop\n",
            "351 lollipop\n",
            "352 vase\n",
            "353 vase\n",
            "354 vase\n",
            "355 lollipop\n",
            "356 vase\n",
            "357 lollipop\n",
            "358 lollipop\n",
            "359 vase\n",
            "360 vase\n",
            "361 lollipop\n",
            "362 lollipop\n",
            "363 lollipop\n",
            "364 lollipop\n",
            "365 lollipop\n",
            "366 vase\n",
            "367 lollipop\n",
            "368 lollipop\n",
            "369 lollipop\n",
            "370 vase\n",
            "371 vase\n",
            "372 lollipop\n",
            "373 vase\n",
            "374 lollipop\n",
            "375 lollipop\n",
            "376 lollipop\n",
            "377 lollipop\n",
            "378 lollipop\n",
            "379 lollipop\n",
            "380 lollipop\n",
            "381 vase\n",
            "382 vase\n",
            "383 lollipop\n",
            "384 vase\n",
            "385 vase\n",
            "386 vase\n",
            "387 lollipop\n",
            "388 vase\n",
            "389 vase\n",
            "390 lollipop\n",
            "391 lollipop\n",
            "392 vase\n",
            "393 vase\n",
            "394 vase\n",
            "395 vase\n",
            "396 lollipop\n",
            "397 vase\n",
            "398 vase\n",
            "399 vase\n",
            "400 lollipop\n",
            "401 vase\n",
            "402 lollipop\n",
            "403 vase\n",
            "404 vase\n",
            "405 lollipop\n",
            "406 lollipop\n",
            "407 lollipop\n",
            "408 vase\n",
            "409 vase\n",
            "410 lollipop\n",
            "411 vase\n",
            "412 vase\n",
            "413 vase\n",
            "414 vase\n",
            "415 lollipop\n",
            "416 lollipop\n",
            "417 lollipop\n",
            "418 vase\n",
            "419 lollipop\n",
            "420 vase\n",
            "421 vase\n",
            "422 vase\n",
            "423 vase\n",
            "424 vase\n",
            "425 vase\n",
            "426 lollipop\n",
            "427 lollipop\n",
            "428 vase\n",
            "429 vase\n",
            "430 lollipop\n",
            "431 lollipop\n",
            "432 vase\n",
            "433 lollipop\n",
            "434 lollipop\n",
            "435 vase\n",
            "436 vase\n",
            "437 vase\n",
            "438 vase\n",
            "439 vase\n",
            "440 vase\n",
            "441 vase\n",
            "442 vase\n",
            "443 vase\n",
            "444 vase\n",
            "445 lollipop\n",
            "446 lollipop\n",
            "447 lollipop\n",
            "448 vase\n",
            "449 vase\n",
            "450 vase\n",
            "451 vase\n",
            "452 vase\n",
            "453 lollipop\n",
            "454 vase\n",
            "455 lollipop\n",
            "456 lollipop\n",
            "457 lollipop\n",
            "458 lollipop\n",
            "459 vase\n",
            "460 vase\n",
            "461 lollipop\n",
            "462 lollipop\n",
            "463 lollipop\n",
            "464 lollipop\n",
            "465 vase\n",
            "466 vase\n",
            "467 vase\n",
            "468 lollipop\n",
            "469 vase\n",
            "470 vase\n",
            "471 vase\n",
            "472 lollipop\n",
            "473 lollipop\n",
            "474 lollipop\n",
            "475 vase\n",
            "476 vase\n",
            "477 vase\n",
            "478 lollipop\n",
            "479 vase\n",
            "480 vase\n",
            "481 lollipop\n",
            "482 vase\n",
            "483 lollipop\n",
            "484 lollipop\n",
            "485 lollipop\n",
            "486 vase\n",
            "487 vase\n",
            "488 lollipop\n",
            "489 lollipop\n",
            "490 vase\n",
            "491 vase\n",
            "492 vase\n",
            "493 lollipop\n",
            "494 vase\n",
            "495 vase\n",
            "496 lollipop\n",
            "497 lollipop\n",
            "498 vase\n",
            "499 vase\n",
            "500 vase\n",
            "501 vase\n",
            "502 vase\n",
            "503 lollipop\n",
            "504 lollipop\n",
            "505 vase\n",
            "506 vase\n",
            "507 vase\n",
            "508 lollipop\n",
            "509 lollipop\n",
            "510 lollipop\n",
            "511 vase\n",
            "512 lollipop\n",
            "513 lollipop\n",
            "514 lollipop\n",
            "515 vase\n",
            "516 vase\n",
            "517 vase\n",
            "518 vase\n",
            "519 vase\n",
            "520 vase\n",
            "521 lollipop\n",
            "522 lollipop\n",
            "523 lollipop\n",
            "524 lollipop\n",
            "525 vase\n",
            "526 lollipop\n",
            "527 vase\n",
            "528 vase\n",
            "529 vase\n",
            "530 lollipop\n",
            "531 lollipop\n",
            "532 lollipop\n",
            "533 vase\n",
            "534 lollipop\n",
            "535 vase\n",
            "536 lollipop\n",
            "537 lollipop\n",
            "538 lollipop\n",
            "539 lollipop\n",
            "540 vase\n",
            "541 lollipop\n",
            "542 lollipop\n",
            "543 lollipop\n",
            "544 lollipop\n",
            "545 vase\n",
            "546 vase\n",
            "547 vase\n",
            "548 lollipop\n",
            "549 vase\n",
            "550 vase\n",
            "551 lollipop\n",
            "552 lollipop\n",
            "553 vase\n",
            "554 vase\n",
            "555 lollipop\n",
            "556 lollipop\n",
            "557 vase\n",
            "558 lollipop\n",
            "559 vase\n",
            "560 vase\n",
            "561 vase\n",
            "562 lollipop\n",
            "563 vase\n",
            "564 vase\n",
            "565 lollipop\n",
            "566 vase\n",
            "567 lollipop\n",
            "568 lollipop\n",
            "569 lollipop\n",
            "570 lollipop\n",
            "571 lollipop\n",
            "572 lollipop\n",
            "573 vase\n",
            "574 lollipop\n",
            "575 vase\n",
            "576 vase\n",
            "577 vase\n",
            "578 vase\n",
            "579 vase\n",
            "580 lollipop\n",
            "581 vase\n",
            "582 vase\n",
            "583 lollipop\n",
            "584 lollipop\n",
            "585 lollipop\n",
            "586 lollipop\n",
            "587 vase\n",
            "588 vase\n",
            "589 lollipop\n",
            "590 vase\n",
            "591 vase\n",
            "592 vase\n",
            "593 vase\n",
            "594 vase\n",
            "595 lollipop\n",
            "596 vase\n",
            "597 lollipop\n",
            "598 lollipop\n",
            "599 lollipop\n",
            "600 vase\n",
            "601 lollipop\n",
            "602 vase\n",
            "603 lollipop\n",
            "604 lollipop\n",
            "605 lollipop\n",
            "606 vase\n",
            "607 lollipop\n",
            "608 lollipop\n",
            "609 vase\n",
            "610 vase\n",
            "611 lollipop\n",
            "612 lollipop\n",
            "613 lollipop\n",
            "614 vase\n",
            "615 vase\n",
            "616 lollipop\n",
            "617 vase\n",
            "618 lollipop\n",
            "619 lollipop\n",
            "620 lollipop\n",
            "621 lollipop\n",
            "622 lollipop\n",
            "623 lollipop\n",
            "624 vase\n",
            "625 vase\n",
            "626 lollipop\n",
            "627 vase\n",
            "628 lollipop\n",
            "629 lollipop\n",
            "630 lollipop\n",
            "631 vase\n",
            "632 vase\n",
            "633 vase\n",
            "634 vase\n",
            "635 vase\n",
            "636 vase\n",
            "637 lollipop\n",
            "638 vase\n",
            "639 vase\n",
            "640 vase\n",
            "641 vase\n",
            "642 vase\n",
            "643 lollipop\n",
            "644 vase\n",
            "645 lollipop\n",
            "646 lollipop\n",
            "647 vase\n",
            "648 lollipop\n",
            "649 vase\n",
            "650 vase\n",
            "651 lollipop\n",
            "652 lollipop\n",
            "653 lollipop\n",
            "654 vase\n",
            "655 lollipop\n",
            "656 lollipop\n",
            "657 vase\n",
            "658 lollipop\n",
            "659 lollipop\n",
            "660 vase\n",
            "661 vase\n",
            "662 vase\n",
            "663 vase\n",
            "664 lollipop\n",
            "665 vase\n",
            "666 lollipop\n",
            "667 vase\n",
            "668 vase\n",
            "669 vase\n",
            "670 lollipop\n",
            "671 lollipop\n",
            "672 vase\n",
            "673 vase\n",
            "674 vase\n",
            "675 vase\n",
            "676 lollipop\n",
            "677 lollipop\n",
            "678 vase\n",
            "679 vase\n",
            "680 lollipop\n",
            "681 vase\n",
            "682 lollipop\n",
            "683 lollipop\n",
            "684 vase\n",
            "685 vase\n",
            "686 lollipop\n",
            "687 vase\n",
            "688 vase\n",
            "689 lollipop\n",
            "690 vase\n",
            "691 lollipop\n",
            "692 lollipop\n",
            "693 vase\n",
            "694 vase\n",
            "695 vase\n",
            "696 vase\n",
            "697 lollipop\n",
            "698 vase\n",
            "699 lollipop\n",
            "700 vase\n",
            "701 lollipop\n",
            "702 vase\n",
            "703 vase\n",
            "704 lollipop\n",
            "705 vase\n",
            "706 lollipop\n",
            "707 vase\n",
            "708 vase\n",
            "709 lollipop\n",
            "710 lollipop\n",
            "711 vase\n",
            "712 lollipop\n",
            "713 lollipop\n",
            "714 lollipop\n",
            "715 lollipop\n",
            "716 vase\n",
            "717 vase\n",
            "718 lollipop\n",
            "719 lollipop\n",
            "720 lollipop\n",
            "721 vase\n",
            "722 lollipop\n",
            "723 lollipop\n",
            "724 vase\n",
            "725 lollipop\n",
            "726 lollipop\n",
            "727 vase\n",
            "728 vase\n",
            "729 vase\n",
            "730 lollipop\n",
            "731 vase\n",
            "732 lollipop\n",
            "733 lollipop\n",
            "734 vase\n",
            "735 lollipop\n",
            "736 vase\n",
            "737 lollipop\n",
            "738 lollipop\n",
            "739 vase\n",
            "740 lollipop\n",
            "741 vase\n",
            "742 lollipop\n",
            "743 vase\n",
            "744 vase\n",
            "745 vase\n",
            "746 vase\n",
            "747 lollipop\n",
            "748 vase\n",
            "749 lollipop\n",
            "750 vase\n",
            "751 lollipop\n",
            "752 vase\n",
            "753 lollipop\n",
            "754 vase\n",
            "755 vase\n",
            "756 lollipop\n",
            "757 vase\n",
            "758 lollipop\n",
            "759 vase\n",
            "760 lollipop\n",
            "761 lollipop\n",
            "762 vase\n",
            "763 lollipop\n",
            "764 vase\n",
            "765 lollipop\n",
            "766 vase\n",
            "767 lollipop\n",
            "768 lollipop\n",
            "769 lollipop\n",
            "770 vase\n",
            "771 lollipop\n",
            "772 vase\n",
            "773 lollipop\n",
            "774 lollipop\n",
            "775 vase\n",
            "776 vase\n",
            "777 vase\n",
            "778 vase\n",
            "779 vase\n",
            "780 lollipop\n",
            "781 lollipop\n",
            "782 vase\n",
            "783 lollipop\n",
            "784 vase\n",
            "785 lollipop\n",
            "786 vase\n",
            "787 vase\n",
            "788 vase\n",
            "789 lollipop\n",
            "790 lollipop\n",
            "791 vase\n",
            "792 vase\n",
            "793 vase\n",
            "794 vase\n",
            "795 vase\n",
            "796 vase\n",
            "797 lollipop\n",
            "798 vase\n",
            "799 vase\n",
            "800 lollipop\n",
            "801 vase\n",
            "802 lollipop\n",
            "803 lollipop\n",
            "804 vase\n",
            "805 vase\n",
            "806 lollipop\n",
            "807 vase\n",
            "808 lollipop\n",
            "809 vase\n",
            "810 lollipop\n",
            "811 lollipop\n",
            "812 lollipop\n",
            "813 vase\n",
            "814 lollipop\n",
            "815 lollipop\n",
            "816 lollipop\n",
            "817 vase\n",
            "818 vase\n",
            "819 vase\n",
            "820 vase\n",
            "821 vase\n",
            "822 vase\n",
            "823 vase\n",
            "824 vase\n",
            "825 vase\n",
            "826 lollipop\n",
            "827 vase\n",
            "828 lollipop\n",
            "829 lollipop\n",
            "830 vase\n",
            "831 lollipop\n",
            "832 vase\n",
            "833 lollipop\n",
            "834 vase\n",
            "835 lollipop\n",
            "836 vase\n",
            "837 vase\n",
            "838 vase\n",
            "839 lollipop\n",
            "840 lollipop\n",
            "841 vase\n",
            "842 lollipop\n",
            "843 vase\n",
            "844 lollipop\n",
            "845 lollipop\n",
            "846 lollipop\n",
            "847 lollipop\n",
            "848 lollipop\n",
            "849 lollipop\n",
            "850 lollipop\n",
            "851 vase\n",
            "852 lollipop\n",
            "853 lollipop\n",
            "854 vase\n",
            "855 vase\n",
            "856 vase\n",
            "857 lollipop\n",
            "858 lollipop\n",
            "859 lollipop\n",
            "860 lollipop\n",
            "861 lollipop\n",
            "862 vase\n",
            "863 lollipop\n",
            "864 lollipop\n",
            "865 vase\n",
            "866 vase\n",
            "867 vase\n",
            "868 vase\n",
            "869 lollipop\n",
            "870 lollipop\n",
            "871 lollipop\n",
            "872 vase\n",
            "873 vase\n",
            "874 lollipop\n",
            "875 lollipop\n",
            "876 vase\n",
            "877 lollipop\n",
            "878 lollipop\n",
            "879 lollipop\n",
            "880 lollipop\n",
            "881 lollipop\n",
            "882 vase\n",
            "883 vase\n",
            "884 lollipop\n",
            "885 lollipop\n",
            "886 vase\n",
            "887 vase\n",
            "888 lollipop\n",
            "889 lollipop\n",
            "890 vase\n",
            "891 vase\n",
            "892 vase\n",
            "893 vase\n",
            "894 lollipop\n",
            "895 vase\n",
            "896 lollipop\n",
            "897 vase\n",
            "898 vase\n",
            "899 vase\n",
            "900 lollipop\n",
            "901 vase\n",
            "902 lollipop\n",
            "903 vase\n",
            "904 lollipop\n",
            "905 vase\n",
            "906 vase\n",
            "907 lollipop\n",
            "908 vase\n",
            "909 vase\n",
            "910 vase\n",
            "911 vase\n",
            "912 vase\n",
            "913 vase\n",
            "914 lollipop\n",
            "915 lollipop\n",
            "916 lollipop\n",
            "917 lollipop\n",
            "918 lollipop\n",
            "919 vase\n",
            "920 lollipop\n",
            "921 vase\n",
            "922 lollipop\n",
            "923 vase\n",
            "924 vase\n",
            "925 vase\n",
            "926 vase\n",
            "927 lollipop\n",
            "928 lollipop\n",
            "929 vase\n",
            "930 lollipop\n",
            "931 lollipop\n",
            "932 vase\n",
            "933 vase\n",
            "934 lollipop\n",
            "935 lollipop\n",
            "936 vase\n",
            "937 vase\n",
            "938 vase\n",
            "939 vase\n",
            "940 vase\n",
            "941 vase\n",
            "942 lollipop\n",
            "943 vase\n",
            "944 lollipop\n",
            "945 lollipop\n",
            "946 vase\n",
            "947 vase\n",
            "948 vase\n",
            "949 lollipop\n",
            "950 lollipop\n",
            "951 lollipop\n",
            "952 lollipop\n",
            "953 vase\n",
            "954 lollipop\n",
            "955 lollipop\n",
            "956 lollipop\n",
            "957 vase\n",
            "958 vase\n",
            "959 lollipop\n",
            "960 vase\n",
            "961 lollipop\n",
            "962 lollipop\n",
            "963 vase\n",
            "964 lollipop\n",
            "965 vase\n",
            "966 vase\n",
            "967 vase\n",
            "968 lollipop\n",
            "969 vase\n",
            "970 vase\n",
            "971 lollipop\n",
            "972 lollipop\n",
            "973 lollipop\n",
            "974 lollipop\n",
            "975 vase\n",
            "976 vase\n",
            "977 lollipop\n",
            "978 lollipop\n",
            "979 lollipop\n",
            "980 vase\n",
            "981 lollipop\n",
            "982 vase\n",
            "983 vase\n",
            "984 lollipop\n",
            "985 lollipop\n",
            "986 lollipop\n",
            "987 vase\n",
            "988 vase\n",
            "989 lollipop\n",
            "990 lollipop\n",
            "991 vase\n",
            "992 vase\n",
            "993 vase\n",
            "994 vase\n",
            "995 vase\n",
            "996 vase\n",
            "997 vase\n",
            "998 lollipop\n",
            "999 vase\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "7MegUFQr5qBj",
        "outputId": "3ca6c505-63f3-4fa0-f22d-6fab3a7e4f56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_37\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_74 (Bidirecti  (None, 2048)             9224192   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " reshape_37 (Reshape)        (None, 1, 2048)           0         \n",
            "                                                                 \n",
            " bidirectional_75 (Bidirecti  (None, 2048)             25174016  \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_78 (Dense)            (None, 2048)              4196352   \n",
            "                                                                 \n",
            " dense_79 (Dense)            (None, 1024)              2098176   \n",
            "                                                                 \n",
            " dense_80 (Dense)            (None, 2)                 2050      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 40,694,786\n",
            "Trainable params: 40,694,786\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = model.predict(sketch_norms[20])\n",
        "sketch_classes_names[a[-1].argmax()]"
      ],
      "metadata": {
        "id": "wBaOUrhDgm8F",
        "outputId": "e63a4666-6f51-46e5-9e3d-baaa971b34bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 193ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'vase'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 344
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(sketch_norms[20])"
      ],
      "metadata": {
        "id": "DeeJE1qUnSP3",
        "outputId": "b6dfabac-7980-46aa-f0ce-073c832f298d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 120ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.08938126, 0.9106187 ],\n",
              "       [0.08938121, 0.91061884],\n",
              "       [0.08938131, 0.9106187 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 345
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(sketch_norms[23])"
      ],
      "metadata": {
        "id": "XAIwsiw3sGTS",
        "outputId": "2aff059b-7b14-4fd2-c142-e96378f5d349",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 80ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.08938128, 0.9106187 ],\n",
              "       [0.08938132, 0.91061866]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 346
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sketch_classes_onehot[20:31]"
      ],
      "metadata": {
        "id": "vRPjTRSVmDIr",
        "outputId": "a694e197-4081-43c0-d77d-b9ce9a8be3e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 0],\n",
              " [0, 1],\n",
              " [0, 1],\n",
              " [0, 1],\n",
              " [0, 1],\n",
              " [1, 0],\n",
              " [1, 0],\n",
              " [1, 0],\n",
              " [1, 0],\n",
              " [0, 1],\n",
              " [0, 1]]"
            ]
          },
          "metadata": {},
          "execution_count": 343
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a[-1]"
      ],
      "metadata": {
        "id": "0FNUTCFnhrQ3",
        "outputId": "5142a44f-fdfd-4e0f-c0c3-391b7ea6f6f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 301
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bunny = np.array(sketches[21])\n",
        "bunny.shape\n",
        "bunny_stroke_loc =  [list(zip(stroke[0],stroke[1]))for stroke in bunny]\n",
        "max(bunny_stroke_loc)\n",
        "\n",
        "image = np.full((400,400,3),(255,255,255),dtype=np.uint8)\n",
        "for stroke in bunny_stroke_loc:\n",
        "  last_point = int(stroke[0][0]),int(stroke[0][1])\n",
        "  for x,y in stroke:\n",
        "    x,y = int(x),int(y)\n",
        "    cv2.line(image, last_point, (x,y), (0,0,0), 2)\n",
        "    last_point = (x,y)\n",
        "display(Image.fromarray(image))"
      ],
      "metadata": {
        "id": "dY_M8bisgL9r",
        "outputId": "2c5ed1c5-ce0f-44a6-b484-2dc3cf066c50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-295-6a237e7d8883>:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  bunny = np.array(sketches[21])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=400x400 at 0x7F5184373AC0>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qQz3xnofsLv2",
        "outputId": "917fbc97-ae47-4c21-dce5-438cd0325108",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 101ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[nan, nan, nan, ..., nan, nan, nan],\n",
              "       [nan, nan, nan, ..., nan, nan, nan],\n",
              "       [nan, nan, nan, ..., nan, nan, nan],\n",
              "       ...,\n",
              "       [nan, nan, nan, ..., nan, nan, nan],\n",
              "       [nan, nan, nan, ..., nan, nan, nan],\n",
              "       [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "from random import random\n",
        "from numpy import array\n",
        "from numpy import cumsum\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import Bidirectional\n",
        " \n",
        "# create a sequence classification instance\n",
        "def get_sequence(n_timesteps):\n",
        "\t# create a sequence of random numbers in [0,1]\n",
        "\tX = array([[random() for _ in range(3)] for _ in range(n_timesteps)])\n",
        "\t# calculate cut-off value to change class values\n",
        "\tlimit = n_timesteps/4.0\n",
        "\t# determine the class outcome for each item in cumulative sequence\n",
        "\ty = array([0 if x < limit else 1 for x in cumsum(X)])\n",
        "\t# reshape input and output data to be suitable for LSTMs\n",
        "\tX = X.reshape(1, n_timesteps, 3)\n",
        "\ty = y.reshape(1, n_timesteps, 3)\n",
        "\treturn X, y\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Tgv2V6gxTLqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_sequence(n_timesteps)"
      ],
      "metadata": {
        "id": "z5cTIa9YhE5q",
        "outputId": "8f53ffd8-0e7c-40c7-d11b-f4d436d28b44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[0.18856484, 0.83249543, 0.63857166],\n",
              "         [0.02608945, 0.61173493, 0.38091465],\n",
              "         [0.60035833, 0.61780448, 0.81659958],\n",
              "         [0.83572071, 0.66909217, 0.82620664],\n",
              "         [0.60983629, 0.57739309, 0.34279736],\n",
              "         [0.92488484, 0.80804231, 0.43278567],\n",
              "         [0.99228968, 0.86938522, 0.14567868],\n",
              "         [0.09280591, 0.21200722, 0.89687278],\n",
              "         [0.45207773, 0.30274   , 0.0257854 ],\n",
              "         [0.08396502, 0.47685503, 0.5966228 ]]]), array([[[0, 0, 0],\n",
              "         [0, 0, 1],\n",
              "         [1, 1, 1],\n",
              "         [1, 1, 1],\n",
              "         [1, 1, 1],\n",
              "         [1, 1, 1],\n",
              "         [1, 1, 1],\n",
              "         [1, 1, 1],\n",
              "         [1, 1, 1],\n",
              "         [1, 1, 1]]]))"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " \n",
        "# define problem properties\n",
        "n_timesteps = 10\n",
        "# define LSTM\n",
        "model = Sequential()\n",
        "model.add(Bidirectional(LSTM(20, return_sequences=True), input_shape=(n_timesteps, 3)))\n",
        "model.add(TimeDistributed(Dense(3, activation='sigmoid')))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Mu2zqI_fc2E6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "LRp8LGMGdEhb",
        "outputId": "437e4eee-ab37-4f31-b3cf-45cc964db590",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_6 (Bidirectio  (None, 10, 40)           3840      \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " time_distributed_6 (TimeDis  (None, 10, 3)            123       \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,963\n",
            "Trainable params: 3,963\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train LSTM\n",
        "for epoch in range(100):\n",
        "\t# generate new random sequence\n",
        "\tX,y = get_sequence(n_timesteps)\n",
        "\t# fit model for one epoch on this sequence\n",
        "\tmodel.fit(X, y, epochs=1, batch_size=1, verbose=0)\n",
        "# evaluate LSTM\n",
        "X,y = get_sequence(n_timesteps)\n",
        "yhat = model.predict(X, verbose=0)\n",
        "for i in range(n_timesteps):\n",
        "\tprint('Expected:', y[0, i], 'Predicted', yhat[0, i])"
      ],
      "metadata": {
        "id": "xdfg1Kkac596",
        "outputId": "b8f7c1b7-d6ee-4a01-aca2-9d7e6e15714b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected: [0 0 0] Predicted [0.29998505 0.31233665 0.62552375]\n",
            "Expected: [0 1 1] Predicted [0.46193483 0.53070325 0.7548416 ]\n",
            "Expected: [1 1 1] Predicted [0.73518914 0.83131474 0.8896696 ]\n",
            "Expected: [1 1 1] Predicted [0.91115403 0.95606333 0.9539727 ]\n",
            "Expected: [1 1 1] Predicted [0.95958245 0.98238033 0.973434  ]\n",
            "Expected: [1 1 1] Predicted [0.97319645 0.9887903  0.977748  ]\n",
            "Expected: [1 1 1] Predicted [0.97938395 0.9917247  0.97778785]\n",
            "Expected: [1 1 1] Predicted [0.98199743 0.99263257 0.9744278 ]\n",
            "Expected: [1 1 1] Predicted [0.98331285 0.9931567  0.9714486 ]\n",
            "Expected: [1 1 1] Predicted [0.9838081  0.99365616 0.9698224 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_sequence(n_timesteps)"
      ],
      "metadata": {
        "id": "QGA9TJv0c9vb",
        "outputId": "a178e37c-6e65-4e11-c5db-3fe0dffa6757",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[0.95687753],\n",
              "         [0.06930357],\n",
              "         [0.89206917],\n",
              "         [0.62924956],\n",
              "         [0.53936265],\n",
              "         [0.5261289 ],\n",
              "         [0.38954884],\n",
              "         [0.05565213],\n",
              "         [0.98006839],\n",
              "         [0.39675545]]]), array([[[0],\n",
              "         [0],\n",
              "         [0],\n",
              "         [1],\n",
              "         [1],\n",
              "         [1],\n",
              "         [1],\n",
              "         [1],\n",
              "         [1],\n",
              "         [1]]]))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}