{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tiitvaino/NAI22_hand_drawn_sketches/blob/main/load_preprocesss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Preprocessing data\n",
        "In this note book sketches are transformed to 100x100 grayscale images, where pixel values are in the range of 0 to 1 and if this sketch was recognized or not.\n",
        "Data is saved to directories /norm_imgs/ and /recognized/, where each file name represents class name."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_vPfQnS2cxVy"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os \n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "import cv2\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Getting data\n",
        "\n",
        "Data is imported from google cloud.\n",
        "In windows run in external terminal: gcloud init --console-only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "zWwaKV41aytV"
      },
      "outputs": [],
      "source": [
        "# loading sketches \n",
        "# NOTE: it will load a lot of data\n",
        "!gsutil -mq cp \"gs://quickdraw_dataset/full/simplified/*.ndjson\" .\n",
        "#!gsutil -mq cp \"gs://quickdraw_dataset/full/simplified/angel.ndjson\" ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Read data in"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "25Ye5V5tfGna"
      },
      "outputs": [],
      "source": [
        "def read_sketch_data(file_name:str, max_nr_elements:int=None, good_only:bool=True)->pd.DataFrame:\n",
        "  \"\"\"\n",
        "  Read from info about one class of sketches data.\n",
        "  If max_nr_elements==None then all info is read.\n",
        "  If good_only==False then all sketces info is saved.\n",
        "  \"\"\"\n",
        "  df = pd.DataFrame(columns= ['word', 'countrycode', 'timestamp', 'recognized', 'key_id', 'drawing'])\n",
        "  nr_elements = 0\n",
        "  with open(file_name) as f:\n",
        "    for row in f.readlines():\n",
        "      data = json.loads(row)\n",
        "      df_row = pd.DataFrame.from_dict(data,orient='index').T\n",
        "      if not df_row['recognized'].iloc[0]:\n",
        "        continue\n",
        "      df = df.append([df_row])\n",
        "      if max_nr_elements != None:\n",
        "        nr_elements+=1\n",
        "        if max_nr_elements <= nr_elements:\n",
        "          break\n",
        "  # get only good pictures\n",
        "  if good_only:\n",
        "    df = df[df.recognized == True]\n",
        "  return df\n",
        "\n",
        "def read_sketches_data(data_files:list=None,max_nr_imgs_per_cls:int=None)->pd.DataFrame:\n",
        "  \"\"\"\"\n",
        "  Read every desired class info into one dataframe.\n",
        "  \"\"\"\n",
        "\n",
        "  dataframes_dict = dict()\n",
        "  for class_name in data_files:\n",
        "    df_sketches = pd.DataFrame(columns= ['word', 'countrycode', 'timestamp', 'recognized', 'key_id', 'drawing'])\n",
        "    df_sketches = df_sketches.append([read_sketch_data(class_name, max_nr_imgs_per_cls)])\n",
        "    word = df_sketches.word.iloc[0]\n",
        "    dataframes_dict[word]=df_sketches\n",
        "  \n",
        "  return dataframes_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Convert strokes to 100x100 images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [],
      "source": [
        "def vector_to_img(vector)->np.array:\n",
        "  def resize_point(x,y,size_from_original)->tuple:\n",
        "    return round(x*size_from_original),round(y*size_from_original)\n",
        "\n",
        "  stroke_locs =  [list(zip(stroke[0],stroke[1]))for stroke in vector]\n",
        "  image = np.full((100,100),255,dtype=np.uint8)\n",
        "  for stroke in stroke_locs:\n",
        "    last_point = resize_point(int(stroke[0][0]),int(stroke[0][1]),0.25)\n",
        "    for x,y in stroke:\n",
        "      new_point = resize_point(int(x),int(y),0.25)\n",
        "      cv2.line(image, last_point, new_point, 0, 2)\n",
        "      last_point = new_point\n",
        "  return image\n",
        "\n",
        "def visualise_sketch(image):\n",
        "  display(Image.fromarray(image))\n",
        "\n",
        "def visualise_representative_sketches(dataframes_dict:dict):\n",
        "  for class_name, df_class in dataframes_dict.items():\n",
        "    print(class_name)\n",
        "    visualise_sketch(vector_to_img(df_class[df_class['recognized']==True]['drawing'].iloc[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Normalise images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "J3qYfQfPcWMO"
      },
      "outputs": [],
      "source": [
        "def preprocess_class(df:pd.DataFrame)->tuple:\n",
        "  norm_imgs = np.asarray(df.apply(lambda row: vector_to_img(row['drawing'])/255.0,axis=1).to_numpy())\n",
        "  recs = df['recognized'].to_numpy()\n",
        "\n",
        "  preprocessed_df = pd.DataFrame({'recognized':recs,'norm_image':norm_imgs})\n",
        "\n",
        "  return preprocessed_df\n",
        "\n",
        "def preprocess_all_classes(dataframes_dict:dict)->dict:\n",
        "  preprocessed_df_dict = {}\n",
        "  for class_name,df_class in dataframes_dict.items():\n",
        "    preprocessed_df = preprocess_class(df_class)\n",
        "    preprocessed_df_dict[class_name] = preprocessed_df\n",
        "  \n",
        "  return preprocessed_df_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save preprocessed data into separated directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_class_sketches(path:str,class_name:str,df_pre_class:pd.DataFrame):\n",
        "  norm_imgs,recs = df_pre_class['norm_image'].to_numpy(),df_pre_class['recognized'].to_numpy()\n",
        "  np.save(f'{path}/norm_imgs/{class_name}.npy',norm_imgs)\n",
        "  np.save(f'{path}/recognized/{class_name}.npy',recs)\n",
        "\n",
        "def create_dir(path:str):\n",
        "  if not os.path.isdir(path):\n",
        "    os.makedirs(path)\n",
        "\n",
        "def save_all_classes(pre_dataframes_dict:dict,path:str='.'):\n",
        "  create_dir(path)\n",
        "  create_dir(f'{path}/norm_imgs')\n",
        "  create_dir(f'{path}/recognized')\n",
        "\n",
        "  for class_name,df_class in pre_dataframes_dict.items():\n",
        "    save_class_sketches(path,class_name,df_class)\n",
        "    \n",
        "  np.save(f'{path}/processed_classes.npy',list(pre_dataframes_dict.keys()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Read data back in"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {},
      "outputs": [],
      "source": [
        "def read_class_sketches(path:str,class_name:str)->pd.DataFrame:\n",
        "  norm_imgs = np.load(f'{path}/norm_imgs/{class_name}.npy',allow_pickle=True)\n",
        "  recs = np.load(f'{path}/recognized/{class_name}.npy',allow_pickle=True)\n",
        "  preprocessed_df = pd.DataFrame({'recognized':recs,'norm_image':norm_imgs})\n",
        "  return preprocessed_df\n",
        "\n",
        "def read_all_classes(path:str='.')->pd.DataFrame:\n",
        "  classes = np.load(f'{path}/processed_classes.npy')\n",
        "  df_list = []\n",
        "  for class_name in classes:\n",
        "    preprocessed_df = read_class_sketches(path,class_name)\n",
        "    preprocessed_df['word'] = class_name\n",
        "    df_list.append(preprocessed_df)\n",
        "  \n",
        "  pre_df = pd.concat(df_list)\n",
        "  pre_df['onehot'] = pre_df.word.str.get_dummies().values.tolist()\n",
        "\n",
        "  return pre_df,classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Run everything and print out representatives sketches for some context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {},
      "outputs": [],
      "source": [
        "def main():\n",
        "  # 10000 pictures takes approximately 10 s\n",
        "  imgs_per_classe = 1000\n",
        "  nr_classes = 10\n",
        "  data_files = list(filter(lambda x: '.ndjson' in x, os.listdir()))\n",
        "  dict_df_raws = read_sketches_data(data_files[:nr_classes],imgs_per_classe)\n",
        "  dict_df_pres = preprocess_all_classes(dict_df_raws)\n",
        "  save_all_classes(dict_df_pres)\n",
        "  visualise_representative_sketches(dict_df_raws)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "e_OlEQBWgkNy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "aircraft carrier\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAAAAABVicqIAAAA0klEQVR4nO3VwQ6EIAxF0VfD//8ysxhUTFAq0knG3G6MCXCgLWpZkkySlBUUy26sjyAk7Ag1UpTYdH3XjztPql+2okz2lpYxuwVqJCxfVbrCOvhwkv9GLA9k6W7xHhXCiz2vtkOykc497qw/33x7ucL601N3xEVkZ7p/c0+8u2mHr6TJP3Q8lrK8WdynS5YVfyOtjBl2PHleu2uwJtk1z7ZRZ2eZ0BLWXmMXZ7TdCTI33vNnBAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBeRXyAXvDIrkvqaGjAAAAAElFTkSuQmCC",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=100x100>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "airplane\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAAAAABVicqIAAABuUlEQVR4nO2YSxbDIAhFNcf9b9kOUpWfLSaPGYzSNPH6QAFTexlW51VZNyF2WQx2DbBKlfRFgGq56I9bANhXHNIpBeqwy7qJplDIlIKmmErQFAZZUrAUrqTHbBftLhIWlBkxwVMEpHMKyF9SCaXATLmLUGAO0zFhWjCajMDjPVYtn8xkX7nPLLLHpybkSIeD0l4M7zYO+YPo86kxfd+cKGS+ga6NCxJVe8tawvVeUacMX+q5lQSqGJBgRCktHlFKw7dy2q7yINynCbS5ZVT1oNvRdfuU8CP5yabvSpCbx2hrxO8I80BkgtwP2NVddygtJXWN2c1/TjsaDRkDSYYM/MHaN+vJplryAteN9eaB0DUphDytvBLClr3FeJwXvoPJFWtskhepZ7Ox2Kiv05t9eMcySu2b7QBklPbvfUQpsM6MVAik3GwOQVCGkSDloRFQNe0sDP7Ioty1Jo+r/hISwdh9kfgaqIsREC4E1SlxSAzD+qgGZzBIWDNJIKKzAtLmZqQywIzZHNCjHJqh00rE8XfERMwcG371sWDfgQMhEfY7dyUkIQlJSEISkpCEJCQhCUlIQhKSEKd9AJ0WedGGbafsAAAAAElFTkSuQmCC",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=100x100>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "alarm clock\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAAAAABVicqIAAACPElEQVR4nO2Y0Y7EIAhFwfT/f5l9mFoVUbhsJ5ts5GnaEU9BBIWFPsJERFSfLOHxcTdUa8qov1bl6U0Yc9n6C4So56CUqiAi4imL+TME4UdpQxEiEfUibE3pGHuKEBFDXmqQnuEJqxCJIq+RIbOeWnKGVqNNIeqF9H82vgYy4gHNILV1ZoyAkGti6vmfGYmJxPCnL6O7phlEDSVpBkDustfA0L/H8uPQaAwU/alEz+7Xcq+JqNEQpDFWg5+VBxemPHvKZ1QKvFNKnb9jbJKH6NEhqSHcM3YVTJiIhTFMoTHxTTG7ELSe9PPqbD7LXRNEgJrCQzJtCWUzQXwTVint4wbdjTvwNFxutZaTIt5G9wkR1bz3fKJT7HP7ZNJ1jxSYKcV+vaegpiwgri3wuUtP7x2PUiFsz+DYgqWVreTOWQBk5xPk/Li3xA3kNyDO2TjOr5CoUuo0vF/4yZRWrZAodqLLchiUSiMQC4oHgwfRpqQoriUTJRHY7bqxqKrT9aHWZ6AKX/4Qm8jA+T7krhUQus6FKckkg4Vwf9oHdiO2Jqn93kNiCymJQ/3orgjGvB4hkG/JH0DeKek7CJiUgLTSW5JYUhxC9CWHDZDXjic7yLcoRgjHKMilTkE+1TXcXc1B7qzhTvHbS1CAwkjj0oT4lLuPHGbYfcvdh2YKit0cXfVWIp2kMMQwpvMfnH6Wbd7VomQS3LqXbFGSKXTfsFatnaxkuuKw/NcafyAHciAHciAHciAHciAHciAHYsoPdNuptCiTWpoAAAAASUVORK5CYII=",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=100x100>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ambulance\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAAAAABVicqIAAABq0lEQVR4nO2Y27LDIAhFwcn//zLnoY0XghcQO50e9otNG1kBFGmQYCYEgPldI6UlxqamEATYdaQLwXrcZPQg+Ka4MCbh8mF0IPgy7cQYelIYuLfEBpCKsbmQG8jzgW/GnmoIe2CqGVuZuQa/0Y323Ix5QVVCB0abk2rZvu0e3YyuDJYTwmLSofrKkMYDP6EQjIKgV4XBvJRtoRMgDUNwSg+SPaFmeErJ6YSL7qF1K1/qKLhWnWqj+tykOYMblDM1EtJwQi5fDUnry9XZ1dzulpKlcmjx8+bOQZ+BkF/o+5DziH8HIc++i1v2Urer99QFIBcV/rk5E0hbIJ9VamaBtKXtWrHKH0x3+7hNBQBwaZEkCInnRfnC5ol09g2k3jbfs+MD8osQSx1XTkiWSdrmLpVpxxiAOVpr00xtfaldC6jsr/7/iam8qjDJWMJVsz6yT3JOaCGn1nOr8uRcU6wJl/kAzhDnlxCN+D45ome4DqQmcaMn0p+Y2RHDzGfhGtuxUi6o+qh1I4bXHgBESzOJjYuS3hK565e6lYAEJCABCUhAAhKQgAQkIAGZ6g9fHmnJoNn4uQAAAABJRU5ErkJggg==",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=100x100>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "angel\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAAAAABVicqIAAACbElEQVR4nO2YS5LEIAhAxcr9r8wsEpGfRjC9mCpZpe3IEwTEABYjQE/OnxkBrQe8tzZhGgKkVND2KNcA4VuUlDpgFCwFaf2b7rr0QNMH3RiBAP3igvDFuy5y9yxIuZ6p/oyl0HsXuTKrxLoK2+O6JcCUIx9lGODxRp6N7UnXwDZdCdo3EhChA8SKn3/YYJDR8wSxlAKgGAWRLSKbLiwZm9uMulZkaDBoSKk6vcZRmk97UVYGZcSJvRiwFr54U32/kSrX5K1w25DbXdOC5FgW3Z2qXeSWK5SGRKW66wL5hBuR9UCkVhnIopa0kTARTKa91OIMpCod+ud9BMNeXFMyMjUsb/ATDNjyZ/dBNkrxIHgs0TuiHbhnDatdMGTsYhqkBdmAQZgtiHM+Wsw2pJTmjXH5QvFrXVjDDaTJSc5J6L2LPn6pL1HrBWAvRW3R0eV1eMgxGUqHtAgeK2BbFotlUVboaMFZOmLYmFbqZa9lNYDABAAdIpbvpPv9SscEKRdnDOMTKbbmVWEgvCWaT36CK5P2oGK2barXT6DzvCRX6c6YzeWxEDbmolnv6zMfFlbFnejGz8bdoTpjfoxutF4OZJLLyfPXs2Qg+ZbfQsa+/+ZknDPo733ITLIO05C5Id+E8EIy5O4nEQU5h9k9mRuScpj5cregJWwKhywxMg5TLdGCHQmH6ZboJyJvWkurTF+CaPpa1xa0un2yvTfkRy67GONpVPtHunZsymY77i6QPSfvKbzrvLyppCDrORCD3O5CmSOorhHqqhf22KjN8RRltmMK+VRCJ+OBHMiBHMiBHMiBHMiBHMiBHMh/h/wBfRXVrqKzJZ0AAAAASUVORK5CYII=",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=100x100>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "animal migration\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAAAAABVicqIAAAA8ElEQVR4nO3VwQ6EIAxF0dbM///ym4UgimUAg4tJbncq6aEtqssa4c0neYGZ9dbssbVT+CrDPmPLrrlPF0NMsxJZWEp9r1NuB4njNqihSsJ2xV1wk58U/7G0iqgSTxkU3g1WP0HMTGPNvm9lBmknq/GRoUwMXrooMmlw8Psgry+Wm5nCiU68gDektEBexvEgWyOqdgWnagWSt62c2pOykPLjA1K+I+srOXNvADm1jh6V47k0UiVlJMeRXotU236hYZvOSZWIxVD3T74iJn9aICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg/458AX5pObdYh4rTAAAAAElFTkSuQmCC",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=100x100>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ant\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAAAAABVicqIAAABZElEQVR4nO2XQZbEIAhEi7zc/8rMYmKjAjbJxFkVq4429UGFGFE0E8AeXrVjj2wKUUA2QWST8ADZjwCOYY02bvxF2bdup+bagpdyOwFAnJTYjxcwop+AO70pu4kj4egacpW6FXxD6Oeh13twTqQvQTWVodvA8e9hRDHmP2h2yn7S5biEWHgae9qujZPVltoqXtVSco7XlAug2u0Ok2nuQXCLAG5Amn0L7FnRdJAVoKXyrPUYZGPLP3Dt3++urpajOxoWV2n9Tvs/oICKb1eTcNZ8cpO5yFJPl4f51CBR5wrF1p3zG8QGAP+K+WODPKNBHfdU5lA0Hk5tvkhEByaRqhdm8baSHIfifcpDktYVmFYx1d4VTvjyLEE0jjqtTk0clpDcZXhH3zzGxY3vA65F/wAyyt59q2SQ29E+gbx69/7vLy1CCCGEEEIIIYQQQgghhBBCCCGEEEIIIYQQQgghhBBCAPwAHq5osX8OQJQAAAAASUVORK5CYII=",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=100x100>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "anvil\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAAAAABVicqIAAABZElEQVR4nO2Y2RLCIAxFidP//2V8am0W4SaQ0enkvqmQ02yESr1xURtKLodEfWJ1B8dG2HZotgCFzHaHQORazUHwPorm0kN5RQinfbRmop40jzNRT5rHmQUIHoIVSHriLwoSrzUIKBNC7vPMDSHCOwCL1yEJoHWXGOQ6lEh8G+1XYfejLuwS+0XvBx5AhGu4g9QSMLhHByYEC18ga2TH4M67PpnmkXTJ6hpJo8CC8EBchu+yOn69ZueQ/f2oIQk9LyGkhyp4ng8kEu+6hMDinuQwjJzsZ3BI5DrphWQxoBm/XF4CkuIIfFtZcgU+IFcSBkHOoaVHIyYsXMyuP3JguHrUvgdyY5E9skf63V04E5LTiU15knIVflBOWAl//zNnLYzq/eTM/sCsu0BUM06fOVCD5kvQDsPfIIyxs2lIvtNkdKT7sIvoOc1YkIIUpCAFKUhBClKQghSkIAUpSEEKUpA/h7wBflVB2SONql8AAAAASUVORK5CYII=",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=100x100>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "apple\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAAAAABVicqIAAABcElEQVR4nO2Y2xKDIAxEN0z//5fpQ7WCirJrdGgn+9A62niaCwSwjIYMAJpPKSWXt6gQA/Lkzn0QTwXktyD2H+MEgJcjeK1vmOfbJ609serLSbUntnPlDZknXl8/AFuiX2SjSdFytUCq/tH2RcHMkHVRHUWM5kyQ7jYo9cuihLtMPykjK+MDsV4GkIWkJJJB/bKEcAxhFD05C5OOkBFLbG8SGHS4FAaSX5M9gtDSSpiQ5vYACwknsdUixUvwhJ2DxXCxFBaSvx83QhSGPhiZzCTyj80rTGMys1kLd3MISYkH7z6bRwMyZyeE65ERz2tkCJfKkT15CMLUmAaRVvU8gxosw+aEnoqUHq8suHkGq+R/NLAVfV6jLOtnN3rtpK2DZcob7djbirOUU2P1LKx17OFHKCAn2bGDZwykruW92/Kuz2rLgzFzYWNpW9sd0MWd6w5kjbq+N25CPDVsPwlIQAISkIAEJCABCUhAAhKQO/QG0axPtFr49GUAAAAASUVORK5CYII=",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=100x100>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "arm\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAAAAABVicqIAAABWklEQVR4nO3WzRKCMAwE4I3j+79yPAClf2I2RS9uDuqMQz7ShhJzkGEAfPtC8OJngji/gvH4gcFVsuV2Oz59X7pPQVYCAOZw94IGqqIQLwoXXCVbBV7EL3VXLZZ2/hTsnlidNWgkW5gzMt01BW9EhnuP7TyFNEZ4sRaWizAopM7LGAxC5U0iQzPFQfJYqUSiqDCSX6w40hpcIStPfDzaU/jtdLCyWPUL6OyeMVtnkKt1LlfVodZ3Kzk3DLFXso8Iza+WWChkr6TKU40IleH5DQHwLAlLGjcAhr7EhTDvDQx70BH0ah0t3F7lDbNYBgDz+Z0dyvQflqUHtcxjmRiJ+MiMRPQm8dNKohHoaSXTbOwgkWro+MC98OzPu2WSauV8uWrJ9uBNE1zfp8+XN0/8aK+cYJfHytUb+TbkrvjJSCREiBAhQoQIESJEiBAhQoQIESJEiBAhQv4LeQHI81a7X24/fgAAAABJRU5ErkJggg==",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=100x100>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyN5ae+6ceWCcLK6cEbj0rRI",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.15 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "fbcaeb40e85a79d3fd704cee83f39fda96f7073b49e73530e1fcddbbd8ef6f62"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
