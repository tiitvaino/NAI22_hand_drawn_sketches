{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tiitvaino/NAI22_hand_drawn_sketches/blob/main/load_preprocesss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Preprocessing data\n",
        "In this note book sketches are transformed to 100x100 grayscale images, where pixel values are in the range of 0 to 1 and if this sketch was recognized or not.\n",
        "Data is saved to directories /norm_imgs/ and /recognized/, where each file name represents class name."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_vPfQnS2cxVy"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os \n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "import cv2\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Getting data\n",
        "\n",
        "Data is imported from google cloud.\n",
        "In windows run in external terminal: gcloud init --console-only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "zWwaKV41aytV"
      },
      "outputs": [],
      "source": [
        "# loading sketches \n",
        "# NOTE: it will load a lot of data\n",
        "!gsutil -mq cp \"gs://quickdraw_dataset/full/simplified/*.ndjson\" ./raw_data\n",
        "\n",
        "# Main classes\n",
        "#!gsutil -mq cp \"gs://quickdraw_dataset/full/simplified/keyboard.ndjson\" ./raw_data\n",
        "#!gsutil -mq cp \"gs://quickdraw_dataset/full/simplified/monkey.ndjson\" ./raw_data\n",
        "#!gsutil -mq cp \"gs://quickdraw_dataset/full/simplified/fish.ndjson\" ./raw_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Read data in"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "25Ye5V5tfGna"
      },
      "outputs": [],
      "source": [
        "def read_sketch_data(file_name:str, max_nr_elements:int=None, good_only:bool=True)->pd.DataFrame:\n",
        "  \"\"\"\n",
        "  Read from info about one class of sketches data.\n",
        "  If max_nr_elements==None then all info is read.\n",
        "  If good_only==False then all sketces info is saved.\n",
        "  \"\"\"\n",
        "  df = pd.DataFrame(columns= ['word', 'countrycode', 'timestamp', 'recognized', 'key_id', 'drawing'])\n",
        "  nr_elements = 0\n",
        "  with open(file_name) as f:\n",
        "    for row in f.readlines():\n",
        "      data = json.loads(row)\n",
        "      df_row = pd.DataFrame.from_dict(data,orient='index').T\n",
        "      if not df_row['recognized'].iloc[0]:\n",
        "        continue\n",
        "      df = df.append([df_row])\n",
        "      if max_nr_elements != None:\n",
        "        nr_elements+=1\n",
        "        if max_nr_elements <= nr_elements:\n",
        "          break\n",
        "  # get only good pictures\n",
        "  if good_only:\n",
        "    df = df[df.recognized == True]\n",
        "\n",
        "  return df.sample(frac = 1)#[:max_nr_elements if max_nr_elements else len(df)]\n",
        "\n",
        "def read_sketches_data(data_files:list=None,max_nr_imgs_per_cls:int=None, good_only:bool=True)->pd.DataFrame:\n",
        "  \"\"\"\"\n",
        "  Read every desired class info into one dataframe.\n",
        "  \"\"\"\n",
        "\n",
        "  dataframes_dict = dict()\n",
        "  for class_name in data_files:\n",
        "    df_sketches = pd.DataFrame(columns= ['word', 'countrycode', 'timestamp', 'recognized', 'key_id', 'drawing'])\n",
        "    df_sketches = df_sketches.append([read_sketch_data(class_name, max_nr_imgs_per_cls,good_only)])\n",
        "    word = df_sketches.word.iloc[0]\n",
        "    dataframes_dict[word]=df_sketches[:1000 if good_only else len(df_sketches)]#TODO HACK\n",
        "  \n",
        "  return dataframes_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Convert strokes to 100x100 images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def vector_to_img(vector)->np.array:\n",
        "  def resize_point(x,y,size_from_original)->tuple:\n",
        "    return round(x*size_from_original),round(y*size_from_original)\n",
        "\n",
        "  stroke_locs =  [list(zip(stroke[0],stroke[1]))for stroke in vector]\n",
        "  image = np.full((100,100),255,dtype=np.uint8)\n",
        "  for stroke in stroke_locs:\n",
        "    last_point = resize_point(int(stroke[0][0]),int(stroke[0][1]),0.25)\n",
        "    for x,y in stroke:\n",
        "      new_point = resize_point(int(x),int(y),0.25)\n",
        "      cv2.line(image, last_point, new_point, 0, 2)\n",
        "      last_point = new_point\n",
        "  return image\n",
        "\n",
        "def visualise_sketch(image):\n",
        "  display(Image.fromarray(image))\n",
        "\n",
        "def visualise_representative_sketches(dataframes_dict:dict):\n",
        "  for class_name, df_class in dataframes_dict.items():\n",
        "    print(class_name)\n",
        "    visualise_sketch(vector_to_img(df_class[df_class['recognized']==True]['drawing'].iloc[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Normalise images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "J3qYfQfPcWMO"
      },
      "outputs": [],
      "source": [
        "def preprocess_class(df:pd.DataFrame)->tuple:\n",
        "  norm_imgs = np.asarray(df.apply(lambda row: vector_to_img(row['drawing'])/255.0,axis=1).to_numpy())\n",
        "  recs = df['recognized'].to_numpy()\n",
        "\n",
        "  preprocessed_df = pd.DataFrame({'recognized':recs,'norm_image':norm_imgs})\n",
        "\n",
        "  return preprocessed_df\n",
        "\n",
        "def preprocess_all_classes(dataframes_dict:dict)->dict:\n",
        "  preprocessed_df_dict = {}\n",
        "  for class_name,df_class in dataframes_dict.items():\n",
        "    preprocessed_df = preprocess_class(df_class)\n",
        "    preprocessed_df_dict[class_name] = preprocessed_df\n",
        "  \n",
        "  return preprocessed_df_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save preprocessed data into separated directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_class_sketches(path:str,class_name:str,df_pre_class:pd.DataFrame):\n",
        "  norm_imgs,recs = df_pre_class['norm_image'].to_numpy(),df_pre_class['recognized'].to_numpy()\n",
        "  np.save(f'{path}/norm_imgs/{class_name}.npy',norm_imgs)\n",
        "  np.save(f'{path}/recognized/{class_name}.npy',recs)\n",
        "\n",
        "def create_dir(path:str):\n",
        "  if not os.path.isdir(path):\n",
        "    os.makedirs(path)\n",
        "\n",
        "def save_all_classes(pre_dataframes_dict:dict,path:str='.'):\n",
        "  create_dir(path)\n",
        "  create_dir(f'{path}/norm_imgs')\n",
        "  create_dir(f'{path}/recognized')\n",
        "\n",
        "  for class_name,df_class in pre_dataframes_dict.items():\n",
        "    save_class_sketches(path,class_name,df_class)\n",
        "  \n",
        "  np.save(f'{path}/processed_classes.npy',list(pre_dataframes_dict.keys()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Read data back in"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "def read_class_sketches(path:str,class_name:str)->pd.DataFrame:\n",
        "  norm_imgs = np.load(f'{path}/norm_imgs/{class_name}.npy',allow_pickle=True)\n",
        "  recs = np.load(f'{path}/recognized/{class_name}.npy',allow_pickle=True)\n",
        "  preprocessed_df = pd.DataFrame({'recognized':recs,'norm_image':norm_imgs})\n",
        "  return preprocessed_df\n",
        "\n",
        "def read_all_classes(path:str='.')->pd.DataFrame:\n",
        "  classes = np.load(f'{path}/processed_classes.npy')\n",
        "  df_list = []\n",
        "  for class_name in classes:\n",
        "    preprocessed_df = read_class_sketches(path,class_name)\n",
        "    preprocessed_df['word'] = class_name\n",
        "    df_list.append(preprocessed_df)\n",
        "  \n",
        "  pre_df = pd.concat(df_list)\n",
        "  pre_df['onehot'] = pre_df.word.str.get_dummies().values.tolist()\n",
        "\n",
        "  return pre_df,classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Run everything and print out representatives sketches for some context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "def main():\n",
        "  # 10000 pictures takes approximately 10 s\n",
        "  imgs_per_main_class = 1000\n",
        "  imgs_per_noise_class = 100\n",
        "  main_classes = ['keyboard','monkey','fish']\n",
        "  main_classes = [f'{class_name}.ndjson' for class_name in main_classes]\n",
        "  dir_name = './raw_data'\n",
        "\n",
        "  # import main classes\n",
        "  main_data_files = list(filter(lambda x: ('.ndjson' in x) and (x in main_classes), os.listdir(dir_name)))\n",
        "  main_data_files = [f'{dir_name}/{file_name}' for file_name in main_data_files]\n",
        "  main_dict_df_raws = read_sketches_data(main_data_files,None,True) # Choose only good sketches for training\n",
        "  main_dict_df_pres = preprocess_all_classes(main_dict_df_raws)\n",
        "  save_all_classes(main_dict_df_pres,'main','./main_norm_imgs')\n",
        "  visualise_representative_sketches(main_dict_df_raws)\n",
        "  \n",
        "  # import noise classes\n",
        "  noise_data_files = list(filter(lambda x:  ('.ndjson' in x) and (x not in main_classes), os.listdir(dir_name)))\n",
        "  noise_data_files = [f'{dir_name}/{file_name}' for file_name in noise_data_files]\n",
        "  noise_dict_df_raws = read_sketches_data(noise_data_files,imgs_per_noise_class,False) # Choose also bad sketches \n",
        "\n",
        "  noise_dict_df_pres = preprocess_all_classes(noise_dict_df_raws)\n",
        "  save_all_classes(noise_dict_df_pres,'noise_norm_imgs')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "e_OlEQBWgkNy"
      },
      "outputs": [],
      "source": [
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyN5ae+6ceWCcLK6cEbj0rRI",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.15 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "fbcaeb40e85a79d3fd704cee83f39fda96f7073b49e73530e1fcddbbd8ef6f62"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
